{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_neo4j import Neo4jGraph, GraphCypherQAChain\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from langchain.schema import Document\n",
    "\n",
    "import re\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"sunsh1ne1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set LLM\n",
    "# llama3.3 has 70B params (see:https://github.com/ollama/ollama?tab=readme-ov-file)\n",
    "# llama3.2 has \n",
    "# llm = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "# llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0, max_tokens=2048) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Raw LLM Output:\n",
      " Here are the extracted medical relationships in the format you requested:\n",
      "\n",
      "(\"Paracetamol\", \"may reduce\", \"Hepatic damage\")\n",
      "(\"Methionine\", \"may reduce\", \"Hepatic damage\")\n",
      "(\"Catecholamines\", \"are synthesized\", \"Phaeochromocytomas\")\n",
      "(\"Vitamin B12\", \"deficiency causes\", \"Neurological complications\")\n",
      "(\"Folate metabolism\", \"is affected by\", \"Vitamin B12 deficiency\")\n",
      "(\"P.T.T. test\", \"should use\", \"Standardised reagent and technique\")\n",
      "(\"Intrinsic clotting abnormality\", \"can be detected by\", \"P.T.T. test\")\n",
      "(\"Commercial reagents\", \"may fail to detect\", \"Intrinsic clotting abnormality\")\n",
      "(\"Cephalin extracts\", \"may be insensitive to\", \"Commercial reagents\")\n",
      "(\"Manufacturers' techniques\", \"may be unreliable for\", \"Commercial reagents\")\n",
      "matches:\n",
      "[('Paracetamol', 'may reduce', 'Hepatic damage'), ('Methionine', 'may reduce', 'Hepatic damage'), ('Catecholamines', 'are synthesized', 'Phaeochromocytomas'), ('Vitamin B12', 'deficiency causes', 'Neurological complications'), ('Folate metabolism', 'is affected by', 'Vitamin B12 deficiency'), ('P.T.T. test', 'should use', 'Standardised reagent and technique'), ('Intrinsic clotting abnormality', 'can be detected by', 'P.T.T. test'), ('Commercial reagents', 'may fail to detect', 'Intrinsic clotting abnormality'), ('Cephalin extracts', 'may be insensitive to', 'Commercial reagents'), (\"Manufacturers' techniques\", 'may be unreliable for', 'Commercial reagents')]\n",
      "Extracted Nodes: ['Standardised reagent and technique', 'Catecholamines', 'Phaeochromocytomas', 'Vitamin B12 deficiency', 'Methionine', 'Folate metabolism', 'Intrinsic clotting abnormality', 'Cephalin extracts', \"Manufacturers' techniques\", 'P.T.T. test', 'Vitamin B12', 'Commercial reagents', 'Neurological complications', 'Hepatic damage', 'Paracetamol']\n",
      "Extracted Relationships: ['(Paracetamol) -[:MAY_REDUCE]-> (Hepatic damage)', '(Methionine) -[:MAY_REDUCE]-> (Hepatic damage)', '(Catecholamines) -[:ARE_SYNTHESIZED]-> (Phaeochromocytomas)', '(Vitamin B12) -[:DEFICIENCY_CAUSES]-> (Neurological complications)', '(Folate metabolism) -[:IS_AFFECTED_BY]-> (Vitamin B12 deficiency)', '(P.T.T. test) -[:SHOULD_USE]-> (Standardised reagent and technique)', '(Intrinsic clotting abnormality) -[:CAN_BE_DETECTED_BY]-> (P.T.T. test)', '(Commercial reagents) -[:MAY_FAIL_TO_DETECT]-> (Intrinsic clotting abnormality)', '(Cephalin extracts) -[:MAY_BE_INSENSITIVE_TO]-> (Commercial reagents)', \"(Manufacturers' techniques) -[:MAY_BE_UNRELIABLE_FOR]-> (Commercial reagents)\"]\n"
     ]
    }
   ],
   "source": [
    "# Read the test file\n",
    "file_path = \"/Users/brianmann/Downloads/test/test_file.txt\"\n",
    "# file_path=\"/Users/brianmann/Downloads/test/pubmed25n0001.xml\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Structure the text for better entity & relationship extraction\n",
    "\n",
    "# Bad Prompt\n",
    "# structured_text = f\"Abstract: {content}\\nExtract medical relationships as structured triples (Entity1, Relationship, Entity2).\"\n",
    "    \n",
    "# Good Prompt\n",
    "structured_text = f'''Abstract: {content}\\nExtract medical relationships as structured triples (Entity1, Relationship, Entity2). Put all elements of a tuple on the same line\n",
    "in the format (\"entity1\", \"relationship\", \"entity2\") . There must be two entities and a relationship and the relationship should not incluee the entities.'''\n",
    "\n",
    "# structured_text = f\"\"\"Abstract: {content}\\nExtract all meaningful relationships from the following medical abstract. \n",
    "# Provide structured triples in this exact format:\n",
    "# (Entity1) - [Relationship] -> (Entity2).\"\"\"\n",
    "\n",
    "\n",
    "# Call Llama3.2 dynamically and extract the response text\n",
    "# This could be a real problem doesn't take very many tokens by default\n",
    "response = llm.invoke(structured_text)\n",
    "# raw_output = llm.invoke(structured_text, max_tokens=1024)\n",
    "\n",
    "# Extract the actual text from the LLM response\n",
    "raw_output = response.content\n",
    "\n",
    "# Print the cleaned raw output (for debugging)\n",
    "print(\"Cleaned Raw LLM Output:\\n\", raw_output)\n",
    "\n",
    "# Extract (Entity1, Relationship, Entity2) triples using regex\n",
    "# matches = re.findall(r'\"(.*?)\" , \"(.*?)\" , \"(.*?)\"', raw_output)\n",
    "matches = re.findall(r'\\(\"([^\"]+)\",\\s*\"([^\"]+)\",\\s*\"([^\"]+)\"\\)', raw_output)\n",
    "\n",
    "print(f\"matches:\\n{matches}\")\n",
    "\n",
    "# Convert extracted triples into nodes and relationships\n",
    "nodes = set()\n",
    "relationships = []\n",
    "\n",
    "for entity1, relation, entity2 in matches:\n",
    "    nodes.add(entity1)\n",
    "    nodes.add(entity2)\n",
    "    relationships.append((entity1, relation, entity2))\n",
    "\n",
    "# Convert to Full Node-Relationship-Node Format\n",
    "formatted_graph = [f\"({e1}) -[:{r.replace(' ', '_').upper()}]-> ({e2})\" for e1, r, e2 in relationships]\n",
    "\n",
    "# Print formatted output\n",
    "print(\"Extracted Nodes:\", list(nodes))\n",
    "print(\"Extracted Relationships:\", formatted_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Nodes: []\n",
      "Extracted Relationships: []\n",
      "\n",
      "Full Node-Relationship-Node Format:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract (Entity1, Relationship, Entity2) triples using regex\n",
    "matches = re.findall(r\"`(.*?)` - `(.*?)` - `(.*?)`\", raw_output)\n",
    "\n",
    "# Convert extracted triples into nodes and relationships\n",
    "nodes = set()\n",
    "relationships = []\n",
    "\n",
    "for entity1, relation, entity2 in matches:\n",
    "    nodes.add(entity1)\n",
    "    nodes.add(entity2)\n",
    "    relationships.append((entity1, relation, entity2))\n",
    "\n",
    "# Convert to Full Node-Relationship-Node Format\n",
    "formatted_graph = [f\"({e1}) -[:{r.replace(' ', '_').upper()}]-> ({e2})\" for e1, r, e2 in relationships]\n",
    "\n",
    "# Print formatted output\n",
    "print(\"Extracted Nodes:\", list(nodes))\n",
    "print(\"Extracted Relationships:\", formatted_graph)\n",
    "print()\n",
    "# Print formatted output\n",
    "print(\"Full Node-Relationship-Node Format:\\n\")\n",
    "for triple in formatted_graph:\n",
    "    print(triple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Total Abstracts: 10\n",
      "\n",
      "ðŸ“Œ Processing Abstract 1/10\n",
      "\n",
      "ðŸ“Œ Processing Abstract 2/10\n",
      "\n",
      "ðŸ“Œ Processing Abstract 3/10\n",
      "\n",
      "ðŸ“Œ Processing Abstract 4/10\n",
      "\n",
      "ðŸ“Œ Processing Abstract 5/10\n",
      "\n",
      "ðŸ“Œ Processing Abstract 6/10\n",
      "\n",
      "ðŸ“Œ Processing Abstract 7/10\n",
      "\n",
      "ðŸ“Œ Processing Abstract 8/10\n",
      "\n",
      "ðŸ“Œ Processing Abstract 9/10\n",
      "\n",
      "ðŸ“Œ Processing Abstract 10/10\n",
      "\n",
      "âœ… Extracted Nodes: []\n",
      "\n",
      "âœ… Extracted Relationships: []\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain_ollama import ChatOllama\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Initialize Llama3.2\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0, max_tokens=2048)\n",
    "\n",
    "# Read test file (each line is a separate abstract)\n",
    "file_path = \"/Users/brianmann/Downloads/test/test_file_small.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    abstracts = file.readlines()  # Read each line as an abstract\n",
    "\n",
    "# Remove empty lines and strip whitespace\n",
    "abstracts = [line.strip() for line in abstracts if line.strip()]\n",
    "\n",
    "print(f\"\\nðŸ“Œ Total Abstracts: {len(abstracts)}\")  # Debugging: See how many abstracts are created\n",
    "\n",
    "# Function to process each abstract (single line)\n",
    "def process_abstract(abstract, index):\n",
    "    print(f\"\\nðŸ“Œ Processing Abstract {index+1}/{len(abstracts)}\")\n",
    "\n",
    "    structured_text = f\"Abstract: {abstract}\\nExtract medical relationships as structured triples (Entity1, Relationship, Entity2).\"\n",
    "\n",
    "    # Call Llama3.2\n",
    "    response = llm.invoke(structured_text)\n",
    "    raw_output = response[\"content\"] if isinstance(response, dict) and \"content\" in response else str(response)\n",
    "\n",
    "    # Extract relationships using regex\n",
    "    matches = re.findall(r\"`(.*?)` - `(.*?)` - `(.*?)`\", raw_output)\n",
    "    return matches\n",
    "\n",
    "# Process abstracts in parallel\n",
    "all_relationships = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    results = executor.map(lambda pair: process_abstract(pair[1], pair[0]), enumerate(abstracts))\n",
    "    for result in results:\n",
    "        all_relationships.extend(result)\n",
    "\n",
    "# Extract nodes\n",
    "all_nodes = set()\n",
    "for entity1, relation, entity2 in all_relationships:\n",
    "    all_nodes.add(entity1)\n",
    "    all_nodes.add(entity2)\n",
    "\n",
    "# Convert to Full Node-Relationship-Node Format\n",
    "formatted_graph = [f\"({e1}) -[:{r.replace(' ', '_').upper()}]-> ({e2})\" for e1, r, e2 in all_relationships]\n",
    "\n",
    "# Print formatted results\n",
    "print(\"\\nâœ… Extracted Nodes:\", list(all_nodes))\n",
    "print(\"\\nâœ… Extracted Relationships:\", formatted_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'\"entity1\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 33\u001b[0m\n\u001b[1;32m      5\u001b[0m     content \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      7\u001b[0m relationship_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[1;32m      8\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m],  \u001b[38;5;66;03m# This must match the placeholder in the template\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n\u001b[0;32m---> 33\u001b[0m formatted_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mrelationship_prompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m response \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39minvoke(formatted_prompt)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# raw_output = llm.invoke(structured_text, max_tokens=1024)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/langchain_core/prompts/prompt.py:183\u001b[0m, in \u001b[0;36mPromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Format the prompt with the inputs.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    A formatted string.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_partial_and_user_variables(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULT_FORMATTER_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate_format\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/string.py:161\u001b[0m, in \u001b[0;36mFormatter.format\u001b[0;34m(self, format_string, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/langchain_core/utils/formatting.py:33\u001b[0m, in \u001b[0;36mStrictFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo arguments should be provided, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meverything should be passed as keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/string.py:165\u001b[0m, in \u001b[0;36mFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, args, kwargs):\n\u001b[1;32m    164\u001b[0m     used_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 165\u001b[0m     result, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mused_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_unused_args(used_args, args, kwargs)\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/string.py:205\u001b[0m, in \u001b[0;36mFormatter._vformat\u001b[0;34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[0m\n\u001b[1;32m    201\u001b[0m     auto_arg_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# given the field_name, find the object it references\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m#  and the argument it came from\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m obj, arg_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m used_args\u001b[38;5;241m.\u001b[39madd(arg_used)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# do any conversion on the resulting object\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/string.py:270\u001b[0m, in \u001b[0;36mFormatter.get_field\u001b[0;34m(self, field_name, args, kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_field\u001b[39m(\u001b[38;5;28mself\u001b[39m, field_name, args, kwargs):\n\u001b[1;32m    268\u001b[0m     first, rest \u001b[38;5;241m=\u001b[39m _string\u001b[38;5;241m.\u001b[39mformatter_field_name_split(field_name)\n\u001b[0;32m--> 270\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# loop through the rest of the field_name, doing\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m#  getattr or getitem as needed\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m is_attr, i \u001b[38;5;129;01min\u001b[39;00m rest:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/string.py:227\u001b[0m, in \u001b[0;36mFormatter.get_value\u001b[0;34m(self, key, args, kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args[key]\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: '\"entity1\"'"
     ]
    }
   ],
   "source": [
    "# Read the test file\n",
    "file_path = \"/Users/brianmann/Downloads/test/test_file.txt\"\n",
    "# filepath=\"/Users/brianmann/Downloads/pubmed25n0001.xml\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "relationship_prompt = PromptTemplate(\n",
    "    input_variables=[\"content\"],  # This must match the placeholder in the template\n",
    "    template=\"\"\"\n",
    "    Given the following biomedical text:\n",
    "\n",
    "    {content}\n",
    "\n",
    "    Identify and extract key medical relationships as structured triples.\n",
    "    The output **MUST** be in **JSON format** with the following structure:\n",
    "\n",
    "    ```json\n",
    "    [\n",
    "        {\"entity1\": \"X-ray\", \"relationship\": \"Induces\", \"entity2\": \"DNA double strand breaks\"},\n",
    "        {\"entity1\": \"Neutral filter elution method\", \"relationship\": \"Detects\", \"entity2\": \"DNA double strand breaks\"}\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "    **Rules:**\n",
    "    1. Use precise, domain-specific biomedical relationships.\n",
    "    2. Include only factual relationships found in the text.\n",
    "    3. Maintain a structured JSON format with \"entity1\", \"relationship\", and \"entity2\".\n",
    "\n",
    "    Return ONLY the JSON object, with no extra text.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "formatted_prompt = relationship_prompt.format(content=content)\n",
    "\n",
    "response = llm.invoke(formatted_prompt)\n",
    "# raw_output = llm.invoke(structured_text, max_tokens=1024)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Iteration:\n",
      " content=\"Here are the extracted key medical relationships:\\n\\n1. **X-ray** \\n    - **Induces**\\n    - **DNA double strand breaks**\\n\\n2. **Neutral filter elution method** \\n    - **Detects**\\n    - **DNA double strand breaks**\\n\\n3. **HpA I restriction endonuclease** \\n    - **Introduces**\\n    - **Double strand cuts in DNA**\\n\\n4. **Cucumber mosaic virus** \\n    - **Has RNAs with sequences of 270 residues from the 3'-terminus**\\n       - **Corresponding to each segment of the influenza virus genome**\\n\\n5. **Influenza virus** \\n    - **Has segments corresponding to each RNA in the genome**\\n       - **Mapped by restriction endonuclease analysis**\\n\\n6. **Poly(A(+))-RNA(tot)** \\n    - **Contains a major peak in the 10-13 S region**\\n       - **Accounting for approximately 35% of the total poly(A(+))-RNA applied**\\n\\n7. **Poly(A(+))-RNA(11S)** \\n    - **Contains a single major peak in the 11S region**\\n       - **Resolving to a single major component**\\n\\n8. **(3)H-cDNA** \\n    - **Made from poly(A(+))-RNA(tot) and poly(A(+))-RNA(11S)**\\n       - **Used for back-hybridization analysis**\\n\\n9. **Poly(A(+))-RNA(11S)** \\n    - **Translates to two major polypeptides**\\n       - **Coded by the 620 NT long and 540 NT long poly(A(+))-RNA respectively**\" additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-02-28T12:34:58.682215Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14386320708, 'load_duration': 150181458, 'prompt_eval_count': 2048, 'prompt_eval_duration': 6291000000, 'eval_count': 343, 'eval_duration': 7869000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-051b168c-add3-4fd5-bc3e-3a3215522d39-0' usage_metadata={'input_tokens': 2048, 'output_tokens': 343, 'total_tokens': 2391} \n",
      "\n",
      "Second Iteration:\n",
      " content=\"After analyzing the text, I extracted the following additional medical relationships:\\n\\n1. **Poly(A(+))-RNA(tot)** \\n   - **Contains a highly abundant class representing 41% of its sequences**\\n   - **Corresponding to 3-5 sequences present in 30,000-50,000 copies/cell**\\n\\n2. **Poly(A(+))-RNA(11S)**\\n   - **Translates to two major polypeptides**\\n   - **Coded by the 620 NT long and 540 NT long poly(A(+))-RNA respectively**\\n   - **Contains a highly abundant class representing 85% of its sequences**\\n\\n3. **Influenza virus ds DNA**\\n   - **Corresponding to each segment of the influenza virus genome**\\n   - **Suitable for molecular cloning and restriction endonuclease mapping**\\n\\n4. **HpA I restriction endonuclease**\\n   - **Used in the production of pure, full-length influenza virus ds DNA's**\\n\\n5. **Neutral filter elution method**\\n   - **Used to detect DNA double strand breaks**\\n\\n6. **X-ray**\\n   - **Used to induce DNA double strand breaks**\\n\\n7. **Cucumber mosaic virus**\\n   - **Has RNAs with sequences of 270 residues from the 3'-terminus corresponding to each segment of the influenza virus genome**\\n\\n8. **Poly(A(+))-RNA(tot) and poly(A(+))-RNA(11S)**\\n   - **Analyzed under denaturing conditions on 2% agarose gel electrophoresis**\\n   - **Demonstrated two major components in both poly(A(+))-RNA populations**\" additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-02-28T12:35:12.805771Z', 'done': True, 'done_reason': 'stop', 'total_duration': 13990318417, 'load_duration': 152605584, 'prompt_eval_count': 2048, 'prompt_eval_duration': 6393000000, 'eval_count': 339, 'eval_duration': 7374000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-76311a77-8fa9-43fa-8f97-9d75c4f8cd4f-0' usage_metadata={'input_tokens': 2048, 'output_tokens': 339, 'total_tokens': 2387} \n",
      "\n",
      "Final LLM Output:\n",
      " content=\"Here is the reformatted data:\\n\\n1. **X-ray**\\n   - **Relationship**: Induces\\n   - **Entity 2**: DNA double strand breaks\\n   \\n2. **Neutral filter elution method**\\n   - **Relationship**: Detects\\n   - **Entity 2**: DNA double strand breaks\\n   \\n3. **HpA I restriction endonuclease**\\n   - **Relationship**: Introduces\\n   - **Entity 2**: Double strand cuts in DNA\\n   \\n4. **Cucumber mosaic virus**\\n   - **Relationship**: Has RNAs with sequences of 270 residues from the 3'-terminus\\n   - **Entity 2**: Corresponding to each segment of the influenza virus genome\\n   \\n5. **Influenza virus**\\n   - **Relationship**: Has segments corresponding to each RNA in the genome\\n   - **Entity 2**: Mapped by restriction endonuclease analysis\\n   \\n6. **Poly(A(+))-RNA(tot)**\\n   - **Relationship**: Contains a major peak in the 10-13 S region\\n   - **Entity 2**: Accounting for approximately 35% of the total poly(A(+))-RNA applied\\n   \\n7. **Poly(A(+))-RNA(11S)**\\n   - **Relationship**: Contains a single major peak in the 11S region\\n   - **Entity 2**: Resolving to a single major component\\n   \\n8. **(3)H-cDNA**\\n   - **Relationship**: Made from poly(A(+))-RNA(tot) and poly(A(+))-RNA(11S)\\n   - **Entity 2**: Used for back-hybridization analysis\\n   \\n9. **Poly(A(+))-RNA(11S)**\\n   - **Relationship**: Translates to two major polypeptides\\n   - **Entity 2**: Coded by the 620 NT long and 540 NT long poly(A(+))-RNA respectively\\n\\n10. **Poly(A(+))-RNA(tot)**\\n    - **Relationship**: Contains a highly abundant class representing 41% of its sequences\\n    - **Entity 2**: Corresponding to 3-5 sequences present in 30,000-50,000 copies/cell\\n    \\n11. **Poly(A(+))-RNA(11S)**\\n    - **Relationship**: Translates to two major polypeptides\\n    - **Entity 2**: Coded by the 620 NT long and 540 NT long poly(A(+))-RNA respectively\\n    - **Relationship**: Contains a highly abundant class representing 85% of its sequences\\n    \\n12. **Influenza virus ds DNA**\\n    - **Relationship**: Corresponding to each segment of the influenza virus genome\\n    - **Entity 2**: Suitable for molecular cloning and restriction endonuclease mapping\\n    \\n13. **HpA I restriction endonuclease**\\n    - **Relationship**: Used in the production of pure, full-length influenza virus ds DNA's\\n    \\n14. **Neutral filter elution method**\\n    - **Relationship**: Used to detect DNA double strand breaks\\n    \\n15. **X-ray**\\n    - **Relationship**: Used to induce DNA double strand breaks\\n    \\n16. **Cucumber mosaic virus**\\n    - **Relationship**: Has RNAs with sequences of 270 residues from the 3'-terminus corresponding to each segment of the influenza virus genome\"  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Read the test file\n",
    "file_path = \"/Users/brianmann/Downloads/test/test_file.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# âœ… Define a flexible prompt (not enforcing JSON)\n",
    "relationship_prompt = f\"\"\"\n",
    "    Given the following text:\n",
    "\n",
    "    {content}\n",
    "\n",
    "    Identify and extract key medical relationships from this text.\n",
    "    \n",
    "    **Guidelines:**\n",
    "    - List all meaningful **biomedical entities**.\n",
    "    - Show how these entities are **related**.\n",
    "    - Format relationships as **structured triples** when possible.\n",
    "    - Provide at least one relationship per line of the document\n",
    "\n",
    "    **Example Output:**\n",
    "    1. **Entity 1**: X-ray\n",
    "       - **Relationship**: Induces\n",
    "       - **Entity 2**: DNA double strand breaks\n",
    "       \n",
    "    2. **Entity 1**: Neutral filter elution method\n",
    "       - **Relationship**: Detects\n",
    "       - **Entity 2**: DNA double strand breaks\n",
    "   \n",
    "   Do not provide any extra output once you have completed the task.\n",
    "    \"\"\"\n",
    "\n",
    "# âœ… Correctly format the prompt\n",
    "# formatted_prompt = relationship_prompt.format(content=content)\n",
    "\n",
    "# âœ… Call the LLM\n",
    "response = llm.invoke(relationship_prompt)\n",
    "\n",
    "# âœ… Print raw output first for inspection\n",
    "print(\"First Iteration:\\n\", response, \"\\n\")\n",
    "\n",
    "# Take the response and feed it as the content\n",
    "content2 = str(response).split(\"additional_kwargs\")[0]\n",
    "\n",
    "# before_additional_kwargs = text.split(\"additional_kwargs\")[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Iteration 2\n",
    "structured_text = f\"\"\"\n",
    "Previously, I provided this text:\n",
    "\n",
    "{content}\n",
    "\n",
    "and you provided these relations:\n",
    "\n",
    "{content2}\n",
    "\n",
    "Now, please extract additional medical relationships from the text I provided.\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(structured_text)\n",
    "\n",
    "# âœ… Print raw output first for inspection\n",
    "print(\"Second Iteration:\\n\", response, \"\\n\")\n",
    "\n",
    "# Take the response and feed it as the content\n",
    "content3 = str(response).split(\"additional_kwargs\")[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Iteration 3\n",
    "relationship_prompt = f\"\"\"\n",
    "    Given the following previous responses:\n",
    "\n",
    "    {content2}\n",
    "\n",
    "    and \n",
    "\n",
    "    {content3}\n",
    "\n",
    "Remove any introduction and format all of the data in the form:\n",
    "    1. **Entity 1**: X-ray\n",
    "       - **Relationship**: Induces\n",
    "       - **Entity 2**: DNA double strand breaks\n",
    "       \n",
    "    2. **Entity 1**: Neutral filter elution method\n",
    "       - **Relationship**: Detects\n",
    "       - **Entity 2**: DNA double strand breaks\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "# âœ… Correctly format the prompt\n",
    "# formatted_prompt = relationship_prompt.format(content2=content2, content3=content3)\n",
    "\n",
    "# âœ… Call the LLM\n",
    "response = llm.invoke(relationship_prompt)\n",
    "\n",
    "response_clean = str(response).split(\"additional_kwargs\")[0]\n",
    "\n",
    "\n",
    "\n",
    "# âœ… Print raw output first for inspection\n",
    "print(\"Final LLM Output:\\n\", response_clean, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying just 10 abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Raw LLM Output:\n",
      " Here is the list of extracted medical relationships:\n",
      "\n",
      "1. Multiple Sclerosis, Myelinotoxicity, Cerebrospinal Fluid\n",
      "2. Alpha Fetoprotein, Neural Tube Defects, Open Neural Tube Defects\n",
      "3. Beta2-Microglobulin, Proximal Tubular Function, Diuresis\n",
      "4. Gluten-Free Diet, Villopathy, Malabsorption\n",
      "5. Papanicolaou Smear, Cigarette Consumption, Oral Health\n",
      "6. Hepatitis B Virus, Polyarteritis, e Ag/Ab System\n",
      "Extracted Nodes: []\n",
      "Extracted Relationships: []\n"
     ]
    }
   ],
   "source": [
    "# Read the test file\n",
    "file_path = \"/Users/brianmann/Downloads/test/test_file_small.txt\"\n",
    "# filepath=\"/Users/brianmann/Downloads/pubmed25n0001.xml\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Structure the text for better entity & relationship extraction\n",
    "structured_text = f\"\"\"Abstract: {content} \\n\n",
    "You are an expert Knowledge Graph creater with the ability to extract relationships from medical research.\n",
    "You must connect two entities and state their relationship from the content provided. Extract medical relationships as structured triples (Entity1, Relationship, Entity2).\n",
    "Don't explain your reasoning just provide me with a list of the tuples that you are able to find. There must be two entities and their relationship which gives a total of three things.\n",
    "\\n\"\"\"\n",
    "\n",
    "# print(structured_text)\n",
    "\n",
    "response = llm.invoke(structured_text)\n",
    "\n",
    "# Extract the actual text from the LLM response\n",
    "# raw_output = response[\"content\"] if isinstance(response, dict) and \"content\" in response else str(response)\n",
    "\n",
    "# Print the cleaned raw output (for debugging)\n",
    "print(\"Cleaned Raw LLM Output:\\n\", response.content)\n",
    "\n",
    "# Extract (Entity1, Relationship, Entity2) triples using regex\n",
    "matches = re.findall(r\"`(.*?)` - `(.*?)` - `(.*?)`\", raw_output)\n",
    "\n",
    "# Convert extracted triples into nodes and relationships\n",
    "nodes = set()\n",
    "relationships = []\n",
    "\n",
    "for entity1, relation, entity2 in matches:\n",
    "    nodes.add(entity1)\n",
    "    nodes.add(entity2)\n",
    "    relationships.append((entity1, relation, entity2))\n",
    "\n",
    "# Convert to Full Node-Relationship-Node Format\n",
    "formatted_graph = [f\"({e1}) -[:{r.replace(' ', '_').upper()}]-> ({e2})\" for e1, r, e2 in relationships]\n",
    "\n",
    "# Print formatted output\n",
    "print(\"Extracted Nodes:\", list(nodes))\n",
    "print(\"Extracted Relationships:\", formatted_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_explore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
