{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jGraph, GraphCypherQAChain\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from langchain.schema import Document\n",
    "\n",
    "import re\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import time\n",
    "\n",
    "from neo4j import GraphDatabase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.2\", temperature=0, max_tokens=2048) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in full abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get questions, answer_key, and ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/brianmann/Downloads/ori_pqal.json\", \"r\") as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "questions = [entry.get(\"QUESTION\", \"N/A\") for entry in json_data.values()]\n",
    "answer_key = [entry.get(\"final_decision\", \"N/A\") for entry in json_data.values()]\n",
    "ids = list(json_data.keys())\n",
    "\n",
    "num_questions = 50\n",
    "\n",
    "questions = questions[:num_questions]\n",
    "answer_key = answer_key[:num_questions]\n",
    "ids = ids[:num_questions]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full abstracts using api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_abstracts(pmid):\n",
    "    # pmid = \"14499029\"\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "    params = {\n",
    "        \"db\": \"pubmed\",\n",
    "        \"id\": pmid,\n",
    "        \"retmode\": \"xml\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    root = ET.fromstring(response.content)\n",
    "\n",
    "    article = root.find('.//PubmedArticle')\n",
    "\n",
    "    # Get title\n",
    "    title = article.find('.//ArticleTitle').text\n",
    "\n",
    "    # Get full abstract, preserving labels\n",
    "    abstract_elements = article.findall('.//Abstract/AbstractText')\n",
    "\n",
    "    abstract_parts = []\n",
    "    for elem in abstract_elements:\n",
    "        if elem.text:\n",
    "            label = elem.attrib.get('Label')\n",
    "            if label:\n",
    "                abstract_parts.append(f\"{label}: {elem.text.strip()}\")\n",
    "            else:\n",
    "                abstract_parts.append(elem.text.strip())\n",
    "\n",
    "    abstract = ' '.join(abstract_parts)\n",
    "\n",
    "    # print(f\"Title: {title}\")\n",
    "    # print(f\"Abstract: {abstract}\")\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstracts = []\n",
    "\n",
    "# for id in ids:\n",
    "#     abstracts.append(read_abstracts(id))\n",
    "#     time.sleep(0.35)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the file without API (if already saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('abstracts_list.txt', 'w') as f:\n",
    "#     for item in abstracts:\n",
    "#         f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('abstracts_list.txt', 'r') as f:\n",
    "    abstracts = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_for_conclusion(abstract: str):\n",
    "    query = f'''\n",
    "    Summarize the conclusion of this abstract. Begin with START and end with FINISH.\n",
    "    Abstract: {abstract}\n",
    "    '''\n",
    "    return query\n",
    "\n",
    "def extract_summary(raw_output: str):\n",
    "    # This handles: \"START\", \"START:\", \"START   \\n\", etc.\n",
    "    pattern = r\"START[:\\s]*([\\s\\S]*?)\\s*FINISH\"\n",
    "    match = re.search(pattern, raw_output, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        print(\"Warning: START/FINISH not found properly.\")\n",
    "        return raw_output.strip()  # fallback\n",
    "\n",
    "def get_conclusion(abstract: str):\n",
    "    structured_text = create_query_for_conclusion(abstract)\n",
    "    response = llm.invoke(structured_text)\n",
    "\n",
    "    # Extract the actual text from the LLM response\n",
    "    raw_output = response.content\n",
    "    return extract_summary(raw_output)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusions = [get_conclusion(abstract) for abstract in abstracts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('conclusions_list.txt', 'w') as f:\n",
    "#     for item in conclusions:\n",
    "#         f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('conclusions_list.txt', 'r') as f:\n",
    "#     conclusions = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_abstracts = []\n",
    "\n",
    "example_ids = [14499029, 14499049]\n",
    "\n",
    "for id in example_ids:\n",
    "    example_abstracts.append(read_abstracts(id))\n",
    "    time.sleep(0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_entities = [\"START Naturopathic clinics, Conventional medical clinics, Community Health Centers, Women aged 40 years or more, Patients with menopausal symptoms FINISH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity_lists = [get_entities(abstract) for abstract in example_abstracts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Key entities from Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(or Key entities from Abstract so it isn't too easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_entities(title: str):\n",
    "    query = f'''List the key entities concisely in this text: {title} \n",
    "    Do not number the items. Start the list with START and end with FINISH\n",
    "    '''\n",
    "    return query\n",
    "\n",
    "# def create_query_entities(title: str):\n",
    "#     query = f'''\n",
    "# List key entities assocciated with the important conclusions concisely. Do not number the items. Start the list with START and end with FINISH.\n",
    "\n",
    "# Example Prompt:{example_abstracts[0]}\n",
    "# Example Answer:{example_entities[0]}\n",
    "\n",
    "# Do not use the entities from the example. Base the entities on the following prompt.\n",
    "\n",
    "# Prompt:{title}\n",
    "# Answer:\n",
    "#     '''\n",
    "#     return query\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_entities(raw_output: str):\n",
    "    # This handles: \"START\", \"START:\", \"START   \\n\", etc.\n",
    "    pattern = r\"START[:\\s]*([\\s\\S]*?)\\s*FINISH\"\n",
    "    match = re.search(pattern, raw_output, re.IGNORECASE)\n",
    "    if match:\n",
    "        content = match.group(1).strip()\n",
    "\n",
    "        # Split into lines and remove leading bullets or dashes\n",
    "        entities = []\n",
    "        for line in content.splitlines():\n",
    "            line = line.strip().lower()\n",
    "            line = re.sub(r\"^[•\\-–\\*]+\\s*\", \"\", line)  # Remove bullet symbols\n",
    "            if line:\n",
    "                entities.append(line)\n",
    "        return entities\n",
    "    else:\n",
    "        print(\"Warning: START/FINISH not found properly.\")\n",
    "        return [raw_output.strip()]  # fallback as single-item list\n",
    "\n",
    "def get_entities(title: str):\n",
    "    structured_text = create_query_entities(title)\n",
    "    response = llm.invoke(structured_text)\n",
    "\n",
    "    # Extract the actual text from the LLM response\n",
    "    raw_output = response.content\n",
    "    # print(raw_output)\n",
    "    return clean_entities(raw_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can choose either titles or full abstract to generate key entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity_lists = [get_entities(title) for title in questions]\n",
    "entity_lists = [get_entities(abstract) for abstract in abstracts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"graph_output.txt\", \"w\") as f:\n",
    "    for id, entity_list in zip(ids, entity_lists):\n",
    "        for entity in entity_list:\n",
    "            entity = entity.replace(\"'\", \"\").strip()\n",
    "            safe_entity = entity.replace('\"', '\\\\\"')  # escape inner double quotes\n",
    "            f.write(f\"({id}) -[:RELATES_TO]-> (\\\"{entity}\\\")\\n\")\n",
    "\n",
    "    for id, conclusion in zip(ids, conclusions):\n",
    "        conclusion = conclusion.replace(\"\\n\", \" \").replace(\"'\", \"\").strip()\n",
    "        safe_conclusion = conclusion.replace('\"', '\\\\\"')\n",
    "        f.write(f\"({id}) -[:CONCLUDES]-> (\\\"{conclusion}\\\")\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into Neo4j successfully.\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Neo4j connection credentials\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"sunsh1ne1\"\n",
    "\n",
    "# Initialize the Neo4j driver\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "def insert_data_to_neo4j(data):\n",
    "    with driver.session() as session:\n",
    "        session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "        for line in data:\n",
    "            line = line.strip()\n",
    "            if not line or ' -[:' not in line or ']->' not in line:\n",
    "                print(f\"Skipping malformed line: {line}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                parts = line.split(' -[:')\n",
    "                node_1 = parts[0].strip()[1:-1]  # Remove surrounding parentheses\n",
    "                relationship_and_node_2 = parts[1].split(']->')\n",
    "                relationship = relationship_and_node_2[0].strip()\n",
    "                node_2 = relationship_and_node_2[1].strip()[1:-1]  # Remove surrounding parentheses\n",
    "\n",
    "                # Clean node names: remove wrapping quotes/parentheses, escape quotes for Cypher\n",
    "                node_1 = node_1.strip(' \"\\'()').replace(\"'\", \"''\")\n",
    "                node_2 = node_2.strip(' \"\\'()').replace(\"'\", \"''\")\n",
    "\n",
    "                cypher_query = f\"\"\"\n",
    "                MERGE (a:Entity {{name: '{node_1}'}})\n",
    "                MERGE (b:Entity {{name: '{node_2}'}})\n",
    "                MERGE (a)-[:{relationship}]->(b)\n",
    "                \"\"\"\n",
    "                session.run(cypher_query)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing line: {line}\")\n",
    "                print(f\"Exception: {e}\")\n",
    "\n",
    "# Read the graph data from the file\n",
    "with open(\"graph_output.txt\", \"r\") as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# Insert the data into Neo4j\n",
    "insert_data_to_neo4j(data)\n",
    "\n",
    "print(\"Data inserted into Neo4j successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Entities in Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_entity_lists = [get_entities(question) for question in questions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mitochondria',\n",
       " 'lace plant leaves',\n",
       " 'programmed cell death',\n",
       " 'remodelling of leaf structure',\n",
       " 'cell death pathways',\n",
       " 'apoptosis mechanisms']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_entity_lists[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Similar Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_articles(entities, top_k=10):\n",
    "    # Normalize entities to lowercase for consistent matching\n",
    "    normalized_entities = [e.lower() for e in entities]\n",
    "\n",
    "    cypher = \"\"\"\n",
    "    WITH $entities AS input_entities\n",
    "    MATCH (article:Entity)-[:RELATES_TO]->(e:Entity)\n",
    "    WHERE toLower(e.name) IN input_entities \n",
    "      AND NOT toLower(article.name) IN input_entities\n",
    "    RETURN article.name AS article_id, COUNT(e) AS shared_entities\n",
    "    ORDER BY shared_entities DESC\n",
    "    LIMIT $top_k\n",
    "    \"\"\"\n",
    "\n",
    "    with driver.session() as session:\n",
    "        result = session.run(cypher, entities=normalized_entities, top_k=top_k)\n",
    "        return result.data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entities = ['Mitochondria', 'Lace plant leaves', 'Programmed cell death', 'Remodeling']\n",
    "# matches = find_similar_articles(entities)\n",
    "\n",
    "# print(\"Top matching articles:\")\n",
    "# for match in matches:\n",
    "#     print(f\"Article ID: {match['article_id']}, Shared Entities: {match['shared_entities']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21645374', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_matching_abstracts = []\n",
    "\n",
    "for question_entity_list in question_entity_lists:\n",
    "    matches = find_similar_articles(question_entity_list)\n",
    "    if matches:\n",
    "        best_match = matches[0]\n",
    "        # print(\"Best matching article:\")\n",
    "        # print(f\"Article ID: {best_match['article_id']}\")\n",
    "        best_matching_abstracts.append(best_match['article_id'])\n",
    "        # print(f\"Shared Entities: {best_match['shared_entities']}\")\n",
    "        # print(f\"Matched Entities: {best_match.get('matched_entities', 'N/A')}\")\n",
    "    else:\n",
    "        # print(\"No matching articles found.\")\n",
    "        best_matching_abstracts.append(\"\")\n",
    "\n",
    "best_matching_abstracts[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use get Conclusion for Abstract found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conclusion_from_kg(pmid):\n",
    "    cypher = \"\"\"\n",
    "    MATCH (:Entity {name: $pmid})-[:CONCLUDES]->(conclusion:Entity)\n",
    "    RETURN conclusion.name AS conclusion_text\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(cypher, pmid=pmid)\n",
    "        record = result.single()\n",
    "        return record[\"conclusion_text\"] if record else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The abstract concludes that mitochondrial dynamics play a critical and early role in developmental programmed cell death (PCD) in the lace plant.  Mitochondrial dynamics were found to be correlated with other organelles during PCD, including chloroplasts and transvacuolar strands. The study also demonstrated the feasibility of using cyclosporine A (CsA) as a treatment to reduce the number of perforations in leaves, suggesting that mitochondrial permeability transition pore formation is involved in PCD.',\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_conclusions = [get_conclusion_from_kg(abstract_id) for abstract_id in best_matching_abstracts]\n",
    "\n",
    "found_conclusions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Answers/Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query(question: str, conclusion: str):\n",
    "    query = f'''\n",
    "    Using this information {conclusion}\n",
    "\n",
    "    Answer the following quesiton with yes, no, or maybe.: {question} \n",
    "    '''\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_answers(question, conclusion):\n",
    "    response = llm.invoke(create_query(question, conclusion))\n",
    "    raw_output = response.content\n",
    "    first_word = raw_output.split()[0].rstrip('.').lower()\n",
    "    return first_word\n",
    "    # answers.append(first_word)\n",
    "    # print(first_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_answers = [generate_answers(question, conclusion) for question, conclusion in zip(questions, found_conclusions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([a ==b for a,b in zip(generated_answers, answer_key)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: Our Answer: yes\tAnswer Key: yes\n",
      "Q2: Our Answer: maybe\tAnswer Key: no\n",
      "Q3: Our Answer: yes\tAnswer Key: yes\n",
      "Q4: Our Answer: maybe\tAnswer Key: no\n",
      "Q5: Our Answer: yes\tAnswer Key: yes\n",
      "Q6: Our Answer: yes\tAnswer Key: yes\n",
      "Q7: Our Answer: yes\tAnswer Key: maybe\n",
      "Q8: Our Answer: maybe\tAnswer Key: no\n",
      "Q9: Our Answer: yes\tAnswer Key: no\n",
      "Q10: Our Answer: yes\tAnswer Key: yes\n",
      "Q11: Our Answer: yes\tAnswer Key: yes\n",
      "Q12: Our Answer: no\tAnswer Key: no\n",
      "Q13: Our Answer: no\tAnswer Key: yes\n",
      "Q14: Our Answer: maybe\tAnswer Key: no\n",
      "Q15: Our Answer: yes\tAnswer Key: yes\n",
      "Q16: Our Answer: yes\tAnswer Key: yes\n",
      "Q17: Our Answer: yes\tAnswer Key: yes\n",
      "Q18: Our Answer: yes\tAnswer Key: yes\n",
      "Q19: Our Answer: yes\tAnswer Key: yes\n",
      "Q20: Our Answer: yes\tAnswer Key: yes\n",
      "Q21: Our Answer: maybe\tAnswer Key: yes\n",
      "Q22: Our Answer: maybe\tAnswer Key: yes\n",
      "Q23: Our Answer: yes\tAnswer Key: yes\n",
      "Q24: Our Answer: maybe\tAnswer Key: yes\n",
      "Q25: Our Answer: yes\tAnswer Key: yes\n",
      "Q26: Our Answer: no\tAnswer Key: no\n",
      "Q27: Our Answer: maybe\tAnswer Key: yes\n",
      "Q28: Our Answer: no\tAnswer Key: maybe\n",
      "Q29: Our Answer: yes\tAnswer Key: yes\n",
      "Q30: Our Answer: no\tAnswer Key: yes\n",
      "Q31: Our Answer: yes\tAnswer Key: no\n",
      "Q32: Our Answer: no\tAnswer Key: maybe\n",
      "Q33: Our Answer: no\tAnswer Key: no\n",
      "Q34: Our Answer: maybe\tAnswer Key: yes\n",
      "Q35: Our Answer: maybe\tAnswer Key: yes\n",
      "Q36: Our Answer: no\tAnswer Key: no\n",
      "Q37: Our Answer: yes\tAnswer Key: no\n",
      "Q38: Our Answer: yes\tAnswer Key: no\n",
      "Q39: Our Answer: yes\tAnswer Key: yes\n",
      "Q40: Our Answer: no\tAnswer Key: no\n",
      "Q41: Our Answer: maybe\tAnswer Key: yes\n",
      "Q42: Our Answer: yes\tAnswer Key: yes\n",
      "Q43: Our Answer: maybe\tAnswer Key: maybe\n",
      "Q44: Our Answer: maybe\tAnswer Key: no\n",
      "Q45: Our Answer: maybe\tAnswer Key: yes\n",
      "Q46: Our Answer: yes\tAnswer Key: yes\n",
      "Q47: Our Answer: yes\tAnswer Key: yes\n",
      "Q48: Our Answer: no\tAnswer Key: yes\n",
      "Q49: Our Answer: maybe\tAnswer Key: yes\n",
      "Q50: Our Answer: no\tAnswer Key: no\n"
     ]
    }
   ],
   "source": [
    "for i, (model_answer, correct_answer) in enumerate(zip(generated_answers, answer_key), 1):\n",
    "    print(f\"Q{i}: Our Answer: {model_answer.lower()}\\tAnswer Key: {correct_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline of using conclusions with perfect retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_answers_perfect_retrieval = [generate_answers(question, conclusion) for question, conclusion in zip(questions, conclusions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([a ==b for a,b in zip(generated_answers_perfect_retrieval, answer_key)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
