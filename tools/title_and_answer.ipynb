{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json ##\n",
    "import pandas as pd\n",
    "\n",
    "file_name = \"../ori_pqal.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "abstracts_dict = {}\n",
    "\n",
    "# Extract question and long answer\n",
    "for entry_id, entry in data.items():\n",
    "    question = entry.get(\"QUESTION\", \"\")\n",
    "    long_answer = entry.get(\"LONG_ANSWER\", \"\")\n",
    "\n",
    "    abstracts_dict[entry_id] = {\"title\": question, \"answer\": long_answer}\n",
    "    \n",
    "\n",
    "abstracts = pd.DataFrame.from_dict(abstracts_dict, orient='index')[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from langchain_neo4j import Neo4jGraph, GraphCypherQAChain\n",
    "from langchain_ollama import ChatOllama\n",
    "# from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "# from langchain_core.documents import Document\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "# from langchain.schema import Document\n",
    "\n",
    "import re\n",
    "# from langchain_ollama import ChatOllama\n",
    "# from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.2\", temperature=0, max_tokens=2048) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships ##\n",
    "\n",
    "Relationships were determined by first extracting raw relationships using llama, then prompting a new GPT model* to find commonalities between the relations list so that we can provide a schema of limited relations to the second pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible_relationships = \"CAUSES, TREATS, DIAGNOSES, REDUCES_RISK_OF, INCREASES_RISK_OF, IS_A_RISK_FACTOR_FOR, IS_ASSOCIATED_WITH, PREDICTS, IS_AS_EFFECTIVE_AS, IS_MORE_EFFECTIVE_THAN, IMPROVES, WORSENS, IS_COST_EFFECTIVE_FOR, INFLUENCES, or IS_USEFUL_FOR\"\n",
    "\n",
    "possible_relationships = \"\"\"\n",
    "CAUSES\n",
    "DOES_NOT_CAUSE\n",
    "TREATS\n",
    "DOES_NOT_TREAT\n",
    "DIAGNOSES\n",
    "DOES_NOT_DIAGNOSE\n",
    "REDUCES_RISK_OF\n",
    "DOES_NOT_REDUCE_RISK_OF\n",
    "INCREASES_RISK_OF\n",
    "DOES_NOT_INCREASE_RISK_OF\n",
    "IS_A_RISK_FACTOR_FOR\n",
    "IS_NOT_A_RISK_FACTOR_FOR\n",
    "IS_ASSOCIATED_WITH\n",
    "IS_NOT_ASSOCIATED_WITH\n",
    "PREDICTS\n",
    "DOES_NOT_PREDICT\n",
    "IS_COST_EFFECTIVE_FOR\n",
    "IS_NOT_COST_EFFECTIVE_FOR\n",
    "INFLUENCES\n",
    "DOES_NOT_INFLUENCE\n",
    "IS_USEFUL_FOR\n",
    "IS_NOT_USEFUL_FOR\"\"\"\n",
    "\n",
    "# IS_AS_EFFECTIVE_AS\n",
    "# IS_NOT_AS_EFFECTIVE_AS\n",
    "# IS_MORE_EFFECTIVE_THAN\n",
    "# IS_NOT_MORE_EFFECTIVE_THAN\n",
    "# IS_LESS_EFFECTIVE_THAN\n",
    "# IS_NOT_LESS_EFFECTIVE_THAN\n",
    "\n",
    "\n",
    "# possible_relationships = \"\"\"\n",
    "# CAUSES\n",
    "# TREATS\n",
    "# DIAGNOSES\n",
    "# REDUCES_RISK_OF\n",
    "# INCREASES_RISK_OF\n",
    "# IS_A_RISK_FACTOR_FOR\n",
    "# IS_ASSOCIATED_WITH\n",
    "# PREDICTS\n",
    "# IS_AS_EFFECTIVE_AS\n",
    "# IS_MORE_EFFECTIVE_THAN\n",
    "# IMPROVES\n",
    "# WORSENS\n",
    "# IS_COST_EFFECTIVE_FOR\n",
    "# INFLUENCES\n",
    "# IS_USEFUL_FOR\n",
    "# DOES_NOT_CAUSE\n",
    "# DOES_NOT_TREAT\n",
    "# DOES_NOT_DIAGNOSE\n",
    "# IS_NOT_A_RISK_FACTOR_FOR\n",
    "# IS_NOT_ASSOCIATED_WITH\n",
    "# DOES_NOT_PREDICT\n",
    "# IS_LESS_EFFECTIVE_THAN\n",
    "# IS_NOT_COST_EFFECTIVE_FOR\n",
    "# DOES_NOT_INFLUENCE\n",
    "# IS_NOT_USEFUL_FOR\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query(title: str, answer: str):\n",
    "    query = f'''\n",
    "    Use the relationships {possible_relationships} to build a knowledge graph with answers to these questions\n",
    "    Abstract Question: {title}\\n Answer: {answer}\n",
    "    Use the only the relationships {possible_relationships} and use as many of the words in the question in the nodes as possible: {title}. Extract medical relationships that provide answers to the question as structured triples (Entity1, Relationship, Entity2). Put all elements of a tuple on the same line\n",
    "    in the format (\"entity1\", \"relationship\", \"entity2\") . The relationship should not incluede the entitiess. Start the list with START and end with FINISH\n",
    "    '''\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Here are the extracted medical relationships in the format you requested:\\n\\n(\"Mitochondria\", \"IS_A_RISK_FACTOR_FOR\", \"Programmed Cell Death\")\\n(\"Mitochondria\", \"REDUCES_RISK_OF\", \"Apoptosis\")\\n(\"Mitochondria\", \"PREDICTS\", \"Cell Death\")\\n(\"Chloroplasts\", \"IS_A_RISK_FACTOR_FOR\", \"Programmed Cell Death\")\\n(\"CsA\", \"TREATS\", \"Inflammation\")\\n(\"CsA\", \"IMPROVES\", \"Plant Growth\")\\n(\"Mitochondria\", \"IS_ASSOCIATED_WITH\", \"Nucleus\")\\n(\"Mitochondria\", \"INFLUENCES\", \"Cellular Dynamics\")\\n\\nNote: Some of these relationships may not be directly related to the specific question about lace plant leaves, but they are extracted from the text and may provide context or supporting information.\\n\\nAlso, note that some relationships like \"REDUCES_RISK_OF\" and \"PREDICTS\" are not explicitly mentioned in the original text, but they can be inferred based on the context.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:21:12.811183Z', 'done': True, 'done_reason': 'stop', 'total_duration': 15166010958, 'load_duration': 845476083, 'prompt_eval_count': 328, 'prompt_eval_duration': 4512000000, 'eval_count': 221, 'eval_duration': 9806000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-25dfe059-1520-4ca9-a6ab-a7cc61f39d83-0' usage_metadata={'input_tokens': 328, 'output_tokens': 221, 'total_tokens': 549}\n",
      "content='Based on the abstract question and answer, I\\'ve extracted the following medical relationships that provide answers to the question:\\n\\n(\"Snellen E chart\", IS_ASSOCIATED_WITH, \"Landolt C chart\")\\n(\"Strabismus amblyopia\", IS_A_RISK_FACTOR_FOR, \"Visual acuity\")\\n(\"Landolt C chart\", PREDICTS, \"Visual acuity\")\\n(\"Snellen E chart\", PREDICTS, \"Visual acuity\")\\n(\"Visual acuity\", IMPROVES, \"Landolt C chart\\'s accuracy in strabismus amblyopia\")\\n(\"Strabismus amblyopia\", WORSENS, \"Landolt C chart\\'s accuracy\")\\n\\nNote that some of these relationships may be implied or inferred from the answer, but they are based on the information provided.\\n\\nAlso, I\\'ve used the following relationships:\\n\\n- IS_ASSOCIATED_WITH: The Snellen E chart is associated with the Landolt C chart.\\n- IS_A_RISK_FACTOR_FOR: Strabismus amblyopia is a risk factor for visual acuity.\\n- PREDICTS: Both charts predict visual acuity.\\n- IMPROVES: Visual acuity improves when using the Landolt C chart in strabismus amblyopia.\\n- WORSENS: The accuracy of the Landolt C chart worsens in strabismus amblyopia.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:21:25.693774Z', 'done': True, 'done_reason': 'stop', 'total_duration': 12858557333, 'load_duration': 42283333, 'prompt_eval_count': 257, 'prompt_eval_duration': 587000000, 'eval_count': 274, 'eval_duration': 12227000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-23eb1175-3307-41f4-bebf-8b1db5a19ed3-0' usage_metadata={'input_tokens': 257, 'output_tokens': 274, 'total_tokens': 531}\n",
      "Error no nodes found for: 16418930\n",
      "content='Here are the extracted medical relationships that provide answers to the question:\\n\\n(\"Aquagenic urticaria\", \"IS_A_RISK_FACTOR_FOR\", \"Syncope during bathing in infants\")\\n(\"Aquagenic urticaria\", \"IS_ASSOCIATED_WITH\", \"Pediatric form of water-induced urticaria\")\\n(\"Aquagenic maladies\", \"IS_A_TYPE_OF\", \"Aquagenic urticaria\")\\n\\nNote: The relationship \"IS_A_TYPE_OF\" is not explicitly mentioned in the original list, but it can be inferred as a synonym for \"CAUSES\". \\n\\nAlso, note that the answer \"Aquagenic maladies\" is not directly related to the question, but rather an alternative term for \"Aquagenic urticaria\", which is the actual condition being discussed.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:21:33.423082Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7723128333, 'load_duration': 33623583, 'prompt_eval_count': 224, 'prompt_eval_duration': 516000000, 'eval_count': 161, 'eval_duration': 7172000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-a639ce34-d7bb-47ab-a033-7cbb502387f3-0' usage_metadata={'input_tokens': 224, 'output_tokens': 161, 'total_tokens': 385}\n",
      "content='Here are the extracted medical relationships in the format you requested:\\n\\n(\"Transanal pull-through\", IS_A_RISK_FACTOR_FOR, \"Poor continence results\")\\n(\"Abdominal approach\", PREDICTS, \"Significantly better continence score\")\\n(\"TERPT group\", INCREASES_RISK_OF, \"Enterocolitis\")\\n(\"TERPT group\", IMPROVES, \"Stool pattern\")\\n(\"Transanal pull-through\", WORSENS, \"Continence results\")\\n(\"Abdominal approach\", IS_MORE_EFFECTIVE_THAN, \"Transanal pull-through\")\\n(\"HD (Hirschsprung\\'s disease)\", INFLUENCES, \"Current surgical management\")\\n\\nNote: Some relationships may not be explicitly stated in the text, but can be inferred based on the context. For example, the relationship between HD and current surgical management is implied by the discussion of the study\\'s findings and their implications for the management of HD.\\n\\nAlso, note that some entities (e.g. \"TERPT group\") are not explicitly defined in the text, but can be assumed to refer to a specific group or population being studied.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:21:44.268221Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10833967625, 'load_duration': 42630375, 'prompt_eval_count': 286, 'prompt_eval_duration': 702000000, 'eval_count': 225, 'eval_duration': 10087000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-d8c2e097-9469-4896-8d69-6d4eff0e3f85-0' usage_metadata={'input_tokens': 286, 'output_tokens': 225, 'total_tokens': 511}\n",
      "Error no nodes found for: 17208539\n",
      "content='Here are the extracted medical relationships that provide answers to the question as structured triples:\\n\\n(\"Mammography screening\", \"IS_ASSOCIATED_WITH\", \"Tailored interventions\")\\n(\"Telephone counseling\", \"PREDICTS\", \"Increased mammography use among HMO women\")\\n(\"Tailored print communications\", \"IS_ASSOCIATED_WITH\", \"Mammography screening\")\\n(\"Barriers\", \"CAUSES\", \"Nonadherence to mammography screening\")\\n(\"Nonadherent women\", \"TREATS\", \"Telephone counseling\")\\n(\"Telephone counseling\", \"IS_AS_EFFECTIVE_AS\", \"Tailored print communications\")\\n(\"Nonadherent women\", \"REDUCES_RISK_OF\", \"Increased mammography use among HMO women\")\\n(\"Mammography screening\", \"IMPROVES\", \"Health outcomes in HMO women\")\\n\\nNote: Some relationships may be implied or inferred from the text, but I\\'ve only extracted the explicit ones mentioned.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:21:53.620783Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9343084541, 'load_duration': 39016541, 'prompt_eval_count': 330, 'prompt_eval_duration': 828000000, 'eval_count': 189, 'eval_duration': 8474000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-d1b3b46a-8926-49bd-97b2-926d5dcdf95e-0' usage_metadata={'input_tokens': 330, 'output_tokens': 189, 'total_tokens': 519}\n",
      "content='Based on the abstract question and answer, here are the extracted medical relationships that provide answers to the question as structured triples:\\n\\n(\"Double Balloon Enteroscopy\", \"IS_AS_EFFECTIVE_AS\", \"Tertiary Referral Center\")\\n(\"Double Balloon Enteroscopy\", \"IS_SAFE_FOR\", \"Community Setting\")\\n(\"Double Balloon Enteroscopy\", \"PREDICTS\", \"Comparable Yield\")\\n(\"Double Balloon Enteroscopy\", \"REDUCES_RISK_OF\", \"Complications\")\\n(\"Community Setting\", \"IS_ASSOCIATED_WITH\", \"Tertiary Referral Center\")\\n\\nNote: The relationships used are:\\n\\n- IS_AS_EFFECTIVE_AS: indicates that the efficacy of DBE is comparable to a tertiary referral center\\n- IS_SAFE_FOR: implies that DBE is safe in a community setting\\n- PREDICTS: suggests that the yield of DBE is predictable and comparable to a tertiary referral center\\n- REDUCES_RISK_OF: indicates that DBE reduces the risk of complications\\n- IS_ASSOCIATED_WITH: establishes an association between the community setting and a tertiary referral center' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:22:03.948155Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10320626250, 'load_duration': 38081666, 'prompt_eval_count': 236, 'prompt_eval_duration': 491000000, 'eval_count': 225, 'eval_duration': 9790000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-af5a68bc-24f2-42a8-8337-858115eb17a7-0' usage_metadata={'input_tokens': 236, 'output_tokens': 225, 'total_tokens': 461}\n",
      "content='Here are the extracted medical relationships that provide answers to the question:\\n\\n(\"Emergency laparotomy\", IS_ASSOCIATED_WITH, \"high rate of mortality\")\\n(\"Age > 70 years\", INCREASES_RISK_OF, \"mortality in emergency general surgery laparotomies\")\\n(\"Increasing acute surgical care manpower\", IMPROVES, \"outcomes in emergency general surgery laparotomies\")\\n(\"Early recognition of patients requiring emergency surgery\", PREDICTS, \"mortality in emergency general surgery laparotomies\")\\n(\"Clear management protocols for emergency surgery patients\", IS_A_RISK_FACTOR_FOR, \"mortality in emergency general surgery laparotomies\")\\n(\"Centralisation of emergency surgical services\", REDUCES_RISK_OF, \"mortality in emergency general surgery laparotomies\")\\n(\"Multidisciplinary teams involving emergency surgeons and care of the elderly physicians\", IS_COST_EFFECTIVE_FOR, \"outcomes in emergency general surgery laparotomies\")\\n(\"Post-discharge care services for elderly patients\", IS_USEFUL_FOR, \"improvement of outcomes in emergency general surgery laparotomies\")\\n\\nNote: Some relationships may be implied or inferred from the text, but I\\'ve tried to extract the most direct and explicit connections.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:22:16.275977Z', 'done': True, 'done_reason': 'stop', 'total_duration': 12316654708, 'load_duration': 42845000, 'prompt_eval_count': 315, 'prompt_eval_duration': 816000000, 'eval_count': 259, 'eval_duration': 11456000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-d3222cea-1a5e-423b-95ef-97766c894945-0' usage_metadata={'input_tokens': 315, 'output_tokens': 259, 'total_tokens': 574}\n",
      "Error no nodes found for: 26037986\n",
      "content='Here are the extracted medical relationships that provide answers to the question:\\n\\n(\"Sleep disorders\", \"IS_ASSOCIATED_WITH\", \"Japanese adult population\")\\n(\"Sleep disorders\", \"REDUCES_RISK_OF\", \"Proper management of sleep and energy related problems\")\\n(\"Older age\", \"IS_ASSOCIATED_WITH\", \"Sleep disorders\")\\n(\"Older age\", \"PREDICTS\", \"Increased risk of sleep disorders\")\\n(\"Gender differences in communicating sleep-related problems\", \"IS_ASSOCIATED_WITH\", \"Sleep disorders\")\\n(\"Regular exercise\", \"IMPROVES\", \"Sleep and energy management\")\\n(\"Multiple morbidities\", \"WORSENS\", \"Sleep disorders\")\\n\\nNote: The relationship \"IS_ASSOCIATED_WITH\" is used to indicate a connection between two entities, while the other relationships are used to describe the nature of that connection.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:22:24.51031Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8222047500, 'load_duration': 45231458, 'prompt_eval_count': 277, 'prompt_eval_duration': 594000000, 'eval_count': 172, 'eval_duration': 7580000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-11b3c518-1642-44c6-aca8-4dc6cc5aea2d-0' usage_metadata={'input_tokens': 277, 'output_tokens': 172, 'total_tokens': 449}\n",
      "content='Based on the abstract question and answer, I\\'ve extracted the relevant medical relationships as structured triples. Here are the tuples:\\n\\n(\"HDL-C\", \"IS_ASSOCIATED_WITH\", \"Low HDL-C\")\\n(\"Carotid intima-media thickness\", \"PREDICTS\", \"Atherosclerosis\")\\n(\"Genetic variants\", \"CAUSES\", \"Mutations causing low HDL-C\")\\n(\"Early carotid atherosclerosis\", \"IS_A_RISK_FACTOR_FOR\", \"Increased carotid intima-media thickness\")\\n\\nNote that the answer does not provide direct evidence for or against the relationship between mutations causing low HDL-C and increased carotid intima-media thickness. However, it suggests that genetic variants identified in the study may be insufficient to promote early carotid atherosclerosis, which implies a lack of association between the two conditions.\\n\\nIf we want to include the answer as a structured triple, we could add:\\n\\n(\"Mutations causing low HDL-C\", \"REDUCES_RISK_OF\", \"Early carotid atherosclerosis\")\\n(\"Increased carotid intima-media thickness\", \"IS_A_RISK_FACTOR_FOR\", \"Atherosclerosis\")\\n\\nHowever, this would require some interpretation of the answer, as it implies that mutations causing low HDL-C may reduce the risk of early carotid atherosclerosis, rather than directly promoting increased carotid intima-media thickness.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:22:37.734272Z', 'done': True, 'done_reason': 'stop', 'total_duration': 13211213333, 'load_duration': 44086875, 'prompt_eval_count': 223, 'prompt_eval_duration': 475000000, 'eval_count': 286, 'eval_duration': 12690000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-4a08e9f2-fd8f-480d-b9a6-7d17f14c2ec9-0' usage_metadata={'input_tokens': 223, 'output_tokens': 286, 'total_tokens': 509}\n",
      "content='Based on the abstract and the provided relationships, here are the extracted triples:\\n\\n(\"Short stay ward\", IS_ASSOCIATED_WITH, \"General children\\'s hospital\")\\n(\"Short stay ward\", IS_ASSOCIATED_WITH, \"Academic children\\'s hospital\")\\n(\"Improved bed efficient care\", PREDICTS, \"Short stay ward\")\\n(\"Cost-effective way\", IMPROVES, \"Short stay ward\")\\n(\"Greater parental satisfaction\", INCREASES_RISK_OF, \"Short stay ward\")\\n(\"Early return of the child with their family to the community\", IS_ASSOCIATED_WITH, \"Short stay ward\")\\n\\nNote that some relationships may be implied but not explicitly stated in the abstract. The above triples are based on the explicit statements provided.\\n\\nAlso, note that the relationship \"IS_A_RISK_FACTOR_FOR\" is not applicable here as there is no mention of a risk factor being associated with the short stay ward.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:22:46.517449Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8759146708, 'load_duration': 45112583, 'prompt_eval_count': 261, 'prompt_eval_duration': 607000000, 'eval_count': 183, 'eval_duration': 8106000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-0cdc1080-9de1-4f82-a8c7-721fa01d640e-0' usage_metadata={'input_tokens': 261, 'output_tokens': 183, 'total_tokens': 444}\n",
      "Error no nodes found for: 10966337\n",
      "content='Based on the abstract question and the provided text, I\\'ve extracted the relevant medical relationships that provide answers to the question as structured triples. Here are the extracted triples:\\n\\n(\"Traffic law reform\", IS_ASSOCIATED_WITH, \"Police enforcement practices\")\\n(\"WHO\", PREDICTS, \"Successful road safety practices globally\")\\n(\"World Bank\", PREDICTS, \"Successful road safety practices globally\")\\n(\"Traffic fatality rates\", REDUCES_RISK_OF, \"Changes in police enforcement practices\")\\n(\"Injury rates\", REDUCES_RISK_OF, \"Changes in police enforcement practices\")\\n\\nNote that some of these relationships may not be directly related to the question, but they provide context and supporting information for the answer.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:22:53.60667Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7076911833, 'load_duration': 43658791, 'prompt_eval_count': 258, 'prompt_eval_duration': 601000000, 'eval_count': 146, 'eval_duration': 6431000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-54045fc6-990a-4c7b-bee8-e00bd4989af0-0' usage_metadata={'input_tokens': 258, 'output_tokens': 146, 'total_tokens': 404}\n",
      "Error no nodes found for: 25432938\n",
      "content='Here are the extracted medical relationships that provide answers to the question:\\n\\n(\"Trauma patients\", \"IS_ASSOCIATED_WITH\", \"anticoagulation therapy complication rate\")\\n(\"anticoagulation therapy\", \"PREDICTS\", \"complication in trauma patients\")\\n(\"trauma patients\", \"INCREASES_RISK_OF\", \"bleeding complications\")\\n(\"bleeding complications\", \"WORSENS\", \"outcome in trauma patients\")\\n(\"Trauma patients have a significant complication rate related to anticoagulation therapy\", \"IS_COST_EFFECTIVE_FOR\", \"prospective studies\")\\n(\"Prospective studies\", \"IMPROVES\", \"determination of appropriate treatment regimen for trauma patients\")\\n(\"anticoagulation therapy\", \"REDUCES_RISK_OF\", \"stroke in non-trauma patients\")  # Not directly relevant, but related to the broader context\\n(\"Trauma patients\", \"IS_A_RISK_FACTOR_FOR\", \"bleeding complications\")\\n\\nNote that some of these relationships may be implied or inferred from the original text, rather than being explicitly stated. Additionally, there may be other relationships that could be extracted from the text, depending on how one interprets the question and the answer.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:23:05.089157Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11467972333, 'load_duration': 46513375, 'prompt_eval_count': 255, 'prompt_eval_duration': 594000000, 'eval_count': 243, 'eval_duration': 10826000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-b15e6d7b-cc60-4aeb-9b2c-7c0a77ae34c1-0' usage_metadata={'input_tokens': 255, 'output_tokens': 243, 'total_tokens': 498}\n",
      "content='Here are the extracted medical relationships that provide answers to the question:\\n\\n(\"MCV\", \"IS_ASSOCIATED_WITH\", \"ASH\")\\n(\"AST/ALT\", \"IS_ASSOCIATED_WITH\", \"ASH\")\\n(\"ASH\", \"REFLECTS\", \"UNDERLYING LIVER DISEASE\")\\n(\"NASH\", \"DIFFERS_FROM\", \"ASH\")\\n(\"Liver Biopsy\", \"MIGHT_PROVE_USEFUL_FOR\", \"Guiding selection of patients for liver biopsy\")\\n(\"Therapy\", \"MIGHT_PROVE_USEFUL_FOR\", \"Targeting therapy\")\\n\\nNote: Some relationships were inferred based on the context of the question and the provided answer.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:23:11.606073Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6505081125, 'load_duration': 44093625, 'prompt_eval_count': 256, 'prompt_eval_duration': 601000000, 'eval_count': 134, 'eval_duration': 5857000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-74cc8184-364b-4c6c-b422-f0241d96fcdf-0' usage_metadata={'input_tokens': 256, 'output_tokens': 134, 'total_tokens': 390}\n",
      "content='Here are the extracted medical relationships that provide answers to the question as structured triples:\\n\\n(\"Family History\", \"IS_ASSOCIATED_WITH\", \"Primary Care Providers\")\\n(\"Family History\", \"PREDICTS\", \"Increased Patient Risk\")\\n(\"Conditions\", \"IS_A_RISK_FACTOR_FOR\", \"Family History\")\\n(\"PCPs\\' Ability\", \"IMPROVES\", \"Identify Patients at High Risk\")\\n(\"Prompts\", \"IS_USEFUL_FOR\", \"PCPs\\' Ability\")\\n(\"Prompts\", \"PREDICTS\", \"Increased Patient Risk\")\\n(\"Conditions\", \"INCREASES_RISK_OF\", \"Patients\")\\n(\"Family History\", \"IS_COST_EFFECTIVE_FOR\", \"Further Studies\")\\n\\nNote: Some relationships may be implied or inferred from the text, but I\\'ve only extracted the explicit ones mentioned.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:23:19.548414Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7930290375, 'load_duration': 44497500, 'prompt_eval_count': 265, 'prompt_eval_duration': 595000000, 'eval_count': 165, 'eval_duration': 7288000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-c12ce2fa-1f11-4946-8aca-bff27baf093d-0' usage_metadata={'input_tokens': 265, 'output_tokens': 165, 'total_tokens': 430}\n",
      "content='Here are the extracted relationships in the format you requested:\\n\\n(\"Emergency US fellowship programs\", \"IMPACTS\", \"emergency medicine residents\\' ultrasound education\")\\n(\"Emergency US fellowship programs\", \"IMPROVES\", \"ultrasound educational experiences\")\\n(\"Emergency medicine residents\", \"PERFORMED\", \"more scans overall\")\\n(\"Emergency US fellowship programs\", \"IS_ASSOCIATED_WITH\", \"bedside US for advanced applications\")\\n(\"Emergency medicine residents\", \"USED\", \"bedside US for more advanced applications\")\\n\\nNote: Some relationships may be implied or inferred from the text, but I\\'ve tried to stick to the explicit statements provided. Let me know if you\\'d like me to clarify or expand on any of these!' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:23:26.395714Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6835713834, 'load_duration': 44037000, 'prompt_eval_count': 238, 'prompt_eval_duration': 482000000, 'eval_count': 144, 'eval_duration': 6308000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-f81587ef-fad9-4291-a4df-ac8f0ee49e96-0' usage_metadata={'input_tokens': 238, 'output_tokens': 144, 'total_tokens': 382}\n",
      "content='Here are the extracted medical relationships that provide answers to the question:\\n\\n(\"Opioid Controlled Therapy\", CAUSES, \"refractory breathlessness\")\\n(\"Palliative Care\", IS_ASSOCIATED_WITH, \"breathlessness management\")\\n(\"Patient-Controlled Therapy\", PREDICTS, \"effective relief from breathlessness\")\\n(\"Opioid Administration\", WORSENS, \"breathlessness symptoms\")\\n(\"Breathlessness in Palliative Care\", REDUCES_RISK_OF, \"opioid-related side effects\")\\n(\"Palliative Care Patients\", INCREASES_RISK_OF, \"refractory breathlessness\")\\n(\"Refactory Breathlessness\", IS_A_RISK_FACTOR_FOR, \"palliative care complications\")\\n(\"Opioid PCT\", IMPROVES, \"breathlessness management outcomes\")\\n(\"Breathlessness Management\", IS_COST_EFFECTIVE_FOR, \"palliative care resource allocation\")\\n\\nNote: Some relationships may be implied or inferred from the question, but I\\'ve tried to extract the most direct and relevant ones.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:23:36.190161Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9782200625, 'load_duration': 45287250, 'prompt_eval_count': 233, 'prompt_eval_duration': 479000000, 'eval_count': 211, 'eval_duration': 9256000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-588b6ba6-ee92-41fb-a78c-e0fa3a640c7a-0' usage_metadata={'input_tokens': 233, 'output_tokens': 211, 'total_tokens': 444}\n",
      "Error no nodes found for: 26578404\n",
      "content='Here are the extracted medical relationships that provide answers to the question:\\n\\n(\"Living-Related Liver Transplantation (LRT)\", \"IS_ASSOCIATED_WITH\", \"Short-term and long-term outcomes after LRT did not differ significantly\")\\n(\"Living-Related Liver Transplantation (LRT)\", \"WORSENS\", \"Risk for the donor in LRT\")\\n(\"Splenorenal Shunt Liver Transplantation (SLT)\", \"IS_A_RISK_FACTOR_FOR\", \"Pediatric liver transplantation\")\\n(\"Splenorenal Shunt Liver Transplantation (SLT)\", \"IS_ASSOCIATED_WITH\", \"First-line therapy in pediatric liver transplantation\")\\n(\"Cadaveric organs\", \"ARE_AVAILABLE_FOR\", \"Countries where LRT is performed\")\\n(\"Living-Related Liver Transplantation (LRT)\", \"PROVIDES\", \"Solution for urgent cases\")\\n(\"Cadaveric grafts\", \"CAN_BE_FOUND_IN_TIME\", \"Urgent cases in which LRT is necessary\")\\n\\nNote: Some relationships may be implied or inferred from the text, but I\\'ve tried to extract the most direct and explicit connections.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:23:47.072734Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10869176625, 'load_duration': 44166250, 'prompt_eval_count': 283, 'prompt_eval_duration': 717000000, 'eval_count': 228, 'eval_duration': 10106000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-613025b2-18ee-4224-8655-e0c04bfd9d9e-0' usage_metadata={'input_tokens': 283, 'output_tokens': 228, 'total_tokens': 511}\n",
      "content='Based on the abstract question and the provided answer, I\\'ve extracted some medical relationships that provide answers to the question. Here are the structured triples:\\n\\n(\"Unvaccinated seniors\", \"IS_ASSOCIATED_WITH\", \"Patterns of knowledge\")\\n(\"Unvaccinated seniors\", \"IS_ASSOCIATED_WITH\", \"Attitudes\")\\n(\"Cluster analyses\", \"PREDICTS\", \"Identifying groups for targeted health messages\")\\n\\nThese relationships capture the idea that unvaccinated seniors have associated patterns of knowledge and attitudes, which can be predicted by cluster analyses to identify groups for targeted health messages.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:23:52.836742Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5751595625, 'load_duration': 37176750, 'prompt_eval_count': 217, 'prompt_eval_duration': 474000000, 'eval_count': 120, 'eval_duration': 5239000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-fcb79958-46fd-4f03-9f43-6df49834c5d3-0' usage_metadata={'input_tokens': 217, 'output_tokens': 120, 'total_tokens': 337}\n",
      "content='Here are the extracted medical relationships that provide answers to the question as structured triples:\\n\\n(\"RPN\", \"IS_A_RISK_FACTOR_FOR\", \"Retroperitoneoscopic Nephrectomy\")\\n(\"RPN\", \"IS_ASSOCIATED_WITH\", \"Porcine Model\")\\n(\"RPN\", \"IS_USEFUL_FOR\", \"Teaching and Practicing Retroperitoneoscopy\")\\n\\nNote: The other relationships you provided do not seem to be directly relevant to the question. Let me know if you\\'d like me to clarify or expand on these triples!' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:23:58.359855Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5510483459, 'load_duration': 44479417, 'prompt_eval_count': 227, 'prompt_eval_duration': 478000000, 'eval_count': 113, 'eval_duration': 4986000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-ed57afee-7996-44c0-9ef2-59c3b3216bcd-0' usage_metadata={'input_tokens': 227, 'output_tokens': 113, 'total_tokens': 340}\n",
      "content='Here are the extracted medical relationships in the format you requested:\\n\\n(\"Resting Heart Rate\", IS_ASSOCIATED_WITH, \"Cardiovascular Risk Factors\")\\n(\"Resting Heart Rate\", PREDICTS, \"Cardiovascular Events\")\\n(\"Sub-Saharan African Population\", INFLUENCES, \"Resting Heart Rate Measurement\")\\n(\"Cardiovascular Risk Assessment\", NEEDS, \"Prospective Studies\")\\n(\"Rural Adult West African Population\", IS_ASSOCIATED_WITH, \"Cardiovascular Risk Factors\")\\n\\nNote: Some relationships may not be explicitly stated in the original text, but can be inferred based on general knowledge of medical research and epidemiology.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:24:04.686895Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6315966833, 'load_duration': 44382125, 'prompt_eval_count': 241, 'prompt_eval_duration': 484000000, 'eval_count': 132, 'eval_duration': 5786000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-0a247850-6269-4c82-8194-2d6acc1b926b-0' usage_metadata={'input_tokens': 241, 'output_tokens': 132, 'total_tokens': 373}\n",
      "Error no nodes found for: 22990761\n",
      "content='Here are the extracted medical relationships that provide answers to the question as structured triples:\\n\\n(\"Hospital preparedness\", \"IS_ASSOCIATED_WITH\", \"Surge capacity\")\\n(\"Hospital preparedness\", \"REDUCES_RISK_OF\", \"Terrorism-related multiple casualty incidents\")\\n(\"Hospital preparedness\", \"PREDICTS\", \"Injury severity distribution\")\\n(\"20% of arriving casualties\", \"IS_A_RISK_FACTOR_FOR\", \"Immediate medical treatment\")\\n(\"National emergency health resources\", \"IMPROVES\", \"Utilisation in preparation phase\")\\n(\"National emergency health resources\", \"IMPROVES\", \"Utilisation on real time\")\\n\\nNote: Some relationships may be implied or inferred from the text, but I\\'ve only extracted the explicit ones mentioned.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:24:12.041986Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7341662625, 'load_duration': 44668708, 'prompt_eval_count': 269, 'prompt_eval_duration': 596000000, 'eval_count': 152, 'eval_duration': 6699000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-45bf9e9f-9a37-4c92-812c-e633b4007c51-0' usage_metadata={'input_tokens': 269, 'output_tokens': 152, 'total_tokens': 421}\n",
      "content='Here are the extracted medical relationships that provide answers to the question:\\n\\n(Peak inspiratory pressure, PREDICTS, outcome)\\n(PEEP, PREDICTS, outcome)\\n(ventilation index values, PREDICTS, outcome)\\n\\nThese triples suggest that peak inspiratory pressure, PEEP, and ventilation index values can predict the outcome of children with malignancy and ARDS.\\n\\nAdditionally, we can also extract some relationships that provide context to these predictions:\\n\\n(Peak inspiratory pressure, IS_ASSOCIATED_WITH, ventilation index values)\\n(PEEP, IS_ASSOCIATED_WITH, ventilation index values)\\n\\nThese triples suggest that peak inspiratory pressure and PEEP are associated with ventilation index values, which is relevant to predicting the outcome of children with malignancy and ARDS.\\n\\nWe can also extract a relationship that provides a potential application of these predictions:\\n\\n(Peak inspiratory pressure, PREDICTS, early application of supportive nonconventional therapies)\\n(PEEP, PREDICTS, early application of supportive nonconventional therapies)\\n(ventilation index values, PREDICTS, early application of supportive nonconventional therapies)\\n\\nThese triples suggest that peak inspiratory pressure, PEEP, and ventilation index values can predict the need for early application of supportive nonconventional therapies in children with malignancy and ARDS.\\n\\nNote: The relationship \"PREDICTS\" is used to indicate that these variables can predict the outcome or the need for a specific treatment.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:24:26.187667Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14133705833, 'load_duration': 44524833, 'prompt_eval_count': 247, 'prompt_eval_duration': 585000000, 'eval_count': 302, 'eval_duration': 13502000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-461853b8-a4d3-4a2d-9fdb-5f80c8b15164-0' usage_metadata={'input_tokens': 247, 'output_tokens': 302, 'total_tokens': 549}\n",
      "Error no nodes found for: 11481599\n",
      "content='Here are the extracted medical relationships that provide answers to the question as structured triples:\\n\\n(\"Secondhand smoke exposure (SHSe)\", \"IS_ASSOCIATED_WITH\", \"Tobacco exposure\")\\n(\"Secondhand smoke exposure (SHSe)\", \"REDUCES_RISK_OF\", \"Tobacco-related health disparities\")\\n(\"Most disadvantaged families\", \"IS_ASSOCIATED_WITH\", \"Vulnerable population\")\\n(\"Most disadvantaged families\", \"INCREASES_RISK_OF\", \"Tobacco exposure\")\\n(\"Most disadvantaged families\", \"IS_ASSOCIATED_WITH\", \"Health disparities\")\\n(\"Innovative SHSe interventions\", \"PREDICTS\", \"Significant health disparities\")\\n(\"Secondhand smoke exposure (SHSe)\", \"IS_A_RISK_FACTOR_FOR\", \"Infants discharged from an NICU\")\\n(\"Protective health behaviors\", \"IMPROVES\", \"Reducing tobacco exposure and health disparities\")\\n\\nNote: Some relationships may be implied or inferred based on the context of the question, but I\\'ve only extracted explicit relationships mentioned in the text.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:24:36.157242Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9957267833, 'load_duration': 41698000, 'prompt_eval_count': 253, 'prompt_eval_duration': 589000000, 'eval_count': 211, 'eval_duration': 9324000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-69c24813-3a24-4bdd-95e9-45d2051e06be-0' usage_metadata={'input_tokens': 253, 'output_tokens': 211, 'total_tokens': 464}\n",
      "content='Here are the extracted medical relationships that provide answers to the question as structured triples:\\n\\n(\"Nomograms\", \"PREDICTS\", \"Biochemical Recurrence\")\\n(\"Nomograms\", \"PREDICTS\", \"Prostate Cancer Specific Mortality (PCSM)\")\\n(\"Nomograms\", \"IS_A_RISK_FACTOR_FOR\", \"Prostate Cancer\")\\n(\"BCR\", \"IS_ASSOCIATED_WITH\", \"Prostate Cancer\")\\n(\"BCR\", \"WORSENS\", \"Clinically Relevant Outcomes\")\\n(\"Nomograms\", \"IS_AS_EFFECTIVE_AS\", \"BCR\")\\n(\"PCSM\", \"IS_COST_EFFECTIVE_FOR\", \"Clinical Decision Making\")\\n(\"Nomograms\", \"PREDICTS\", \"More Clinically Relevant Prostate Cancer Outcomes\")\\n\\nNote: Some relationships may be implied or inferred from the text, but I\\'ve tried to extract only the most direct and explicit connections.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:24:44.826078Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8654268333, 'load_duration': 45626750, 'prompt_eval_count': 256, 'prompt_eval_duration': 589000000, 'eval_count': 182, 'eval_duration': 8018000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-5d2b3138-9f5e-4caa-a1d7-27295641253d-0' usage_metadata={'input_tokens': 256, 'output_tokens': 182, 'total_tokens': 438}\n",
      "content='Here are the extracted medical relationships that provide answers to the question as structured triples:\\n\\n(\"Mechanical dysfunction\", \"IS_A_RISK_FACTOR_FOR\", \"Somatisation\")\\n(\"Self-reported mechanical factors\", \"IS_ASSOCIATED_WITH\", \"Psychological factors\")\\n(\"Chronic oro-facial pain\", \"IS_ASSOCIATED_WITH\", \"Somatisation\")\\n(\"Occlusal adjustments\", \"REDUCES_RISK_OF\", \"No justification in many cases\")\\n(\"Surgery\", \"REDUCES_RISK_OF\", \"No justification in many cases\")\\n\\nNote: The relationships used are:\\n\\n- IS_A_RISK_FACTOR_FOR: indicating that mechanical dysfunction is a risk factor for somatisation\\n- IS_ASSOCIATED_WITH: indicating an association between self-reported mechanical factors and psychological factors, and chronic oro-facial pain and somatisation\\n- REDUCES_RISK_OF: indicating that occlusal adjustments and surgery reduce the risk of certain outcomes (in this case, no justification in many cases)\\n- No justification in many cases is a form of \"WORSENS\"' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:24:55.085839Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10247671458, 'load_duration': 45266833, 'prompt_eval_count': 272, 'prompt_eval_duration': 599000000, 'eval_count': 216, 'eval_duration': 9602000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-0e39d35a-3a09-4270-901f-4c8b0fad594c-0' usage_metadata={'input_tokens': 272, 'output_tokens': 216, 'total_tokens': 488}\n",
      "content='Here are the extracted medical relationships that provide answers to the question:\\n\\n(\"Amblyopia\", \"IS_ASSOCIATED_WITH\", \"Visual loss\")\\n(\"Visual loss\", \"PREDICTS\", \"Recovery of visual function in the amblyopic eye\")\\n(\"Recovery of visual function in the amblyopic eye\", \"IMPROVES\", \"Visual function\")\\n(\"Visual loss in the fellow eye\", \"CAUSES\", \"Improvement appears to be sustained\")\\n\\nNote: The relationship \"IS_ASSOCIATED_WITH\" is used because Amblyopia and Visual loss are related concepts, and the other relationships are used to describe the causal or predictive relationship between these concepts.\\n\\nAlso, note that there is no direct answer to the question \"is visual loss permanent?\" in the provided text. However, the extracted relationships suggest that recovery of visual function can occur over time, which implies that visual loss is not necessarily permanent.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:25:03.742879Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8645414167, 'load_duration': 42078375, 'prompt_eval_count': 255, 'prompt_eval_duration': 583000000, 'eval_count': 185, 'eval_duration': 8018000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-78a56846-33d4-4417-ba89-e511d42a3cf1-0' usage_metadata={'input_tokens': 255, 'output_tokens': 185, 'total_tokens': 440}\n",
      "content='Based on the abstract question and answer, I\\'ve extracted the following medical relationships that provide answers to the question:\\n\\n(\"Epidural analgesia\", \"IS_ASSOCIATED_WITH\", \"Labor analgesia\")\\n(\"Epidural analgesia\", \"IS_USEFUL_FOR\", \"Pain management during labor\")\\n(\"Standard of effective analgesia\", \"IS_A_RISK_FACTOR_FOR\", \"Suboptimal response to epidural analgesia\")\\n(\"Suboptimal response to epidural analgesia\", \"REQUIRES_FURTHER_STUDY\", \"Further studies\")\\n(\"Pregnant women\", \"ADHERES_TO\", \"Labor analgesia process\")\\n(\"Labor analgesia process\", \"IS_QUICKLY_IMPLEMENTSED\", \"Implementation of labor analgesia\")\\n(\"Implementation of labor analgesia\", \"IS_SAFE\", \"Safe implementation of labor analgesia\")\\n\\nNote that some relationships may be implied or inferred from the text, but I\\'ve only extracted the most direct and explicit relationships.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:25:13.483989Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9729959583, 'load_duration': 38925542, 'prompt_eval_count': 269, 'prompt_eval_duration': 591000000, 'eval_count': 209, 'eval_duration': 9098000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-e7bacfb9-39da-43c3-a0e5-22cd0e004f4e-0' usage_metadata={'input_tokens': 269, 'output_tokens': 209, 'total_tokens': 478}\n",
      "content='Based on the abstract question and answer, I\\'ve extracted some medical relationships that provide answers to the question. Here are the structured triples:\\n\\n(\"HER2 immunoreactivity\", \"IS_ASSOCIATED_WITH\", \"Urothelial carcinoma\")\\n(\"HER2 immunoreactivity\", \"PREDICTS\", \"Prognostic information\")\\n(\"Advanced urothelial carcinoma patients with adjuvant M-VEC\", \"INFLUENCES\", \"HER2 immunoreactivity\")\\n(\"HER2 immunoreactivity\", \"IS_USEFUL_FOR\", \"Locally advanced urothelial carcinoma patients\")\\n\\nNote that some relationships may be implied or inferred from the question and answer, but I\\'ve tried to stick to the explicit relationships mentioned in the text.\\n\\nAlso, it\\'s worth noting that the answer suggests a limited prognostic value for HER2 immunoreactivity in advanced urothelial carcinoma patients with adjuvant M-VEC. This implies a relationship of \"WORSENS\" or \"REDUCES\" between HER2 immunoreactivity and prognostic information in this context, but it\\'s not explicitly stated.\\n\\nIf you\\'d like to add more relationships or clarify any of these triples, please let me know!' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:25:24.836628Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11339548833, 'load_duration': 42410125, 'prompt_eval_count': 244, 'prompt_eval_duration': 478000000, 'eval_count': 248, 'eval_duration': 10817000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-e711017f-3495-4088-ab92-27bdb8b41eaf-0' usage_metadata={'input_tokens': 244, 'output_tokens': 248, 'total_tokens': 492}\n",
      "content='Based on the abstract question and answer, I\\'ve extracted the relevant medical relationships that provide answers to the question. Here are the structured triples:\\n\\n(\"Halofantrine\", \"IS Ototoxic\", \"Yes\")\\n(\"Halofantrine\", \"HAS PATHOLOGICAL EFFECTS ON COCHLEA HISTOLOGY\", \"Mild to moderate\")\\n(\"Cochlea histology\", \"IS AFFECTED BY\", \"Halofantrine\")\\n\\nNote: The relationship \"IS Ototoxic\" is a direct answer to the question, while the other two triples provide supporting evidence for this answer.\\n\\nAlternatively, if we want to represent the relationships in a more general format without including the entities:\\n\\n(\"Ototoxicity\", \"CAUSES\", \"Halofantrine\")\\n(\"Cochlea histology\", \"IS AFFECTED BY\", \"Halofantrine\")\\n\\nThese triples capture the essence of the relationship between halofantrine and ototoxicity, with the latter being a more general concept that encompasses the specific effects on cochlea histology.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:25:34.855405Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10009518708, 'load_duration': 42423708, 'prompt_eval_count': 221, 'prompt_eval_duration': 483000000, 'eval_count': 219, 'eval_duration': 9483000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-01239f07-dcb4-4dbf-b7d1-4019a40ea9b0-0' usage_metadata={'input_tokens': 221, 'output_tokens': 219, 'total_tokens': 440}\n",
      "content='Here are the extracted medical relationships that provide answers to the question:\\n\\n(\"Visceral Adipose Tissue Area Measurement\", PREDICTS, \"Changes in Visceral Adipose Tissue Volume and Body Weight\")\\n(\"VAT Area at a CT slice 3cm above the lower margin of L3\", IS_ASSOCIATED_WITH, \"Interval Changes in VAT Volume and Body Weight\")\\n(\"VAT Area Measurement\", IS_COST_EFFECTIVE_FOR, \"Visceral Adipose Tissue Volume Measurement\")\\n(\"VAT Area Measurement\", IMPROVES, \"Assessment of Visceral Adipose Tissue Volume and Body Weight\")\\n(\"VAT Area at a CT slice 3cm above the lower margin of L3\", IS_AS_EFFECTIVE_AS, \"VAT Area Measurement\")\\n\\nNote: The relationships used are:\\n\\n- PREDICTS: indicates that one entity predicts or correlates with another\\n- IS_ASSOCIATED_WITH: indicates an association between two entities\\n- IS_COST_EFFECTIVE_FOR: indicates that one entity is cost-effective for another\\n- IMPROVES: indicates that one entity improves upon or enhances another\\n- IS_AS_EFFECTIVE_AS: indicates that one entity is as effective as another' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:25:46.638318Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11772450708, 'load_duration': 43137000, 'prompt_eval_count': 284, 'prompt_eval_duration': 701000000, 'eval_count': 249, 'eval_duration': 11027000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-dd933b00-1926-47b1-9947-f096f3701766-0' usage_metadata={'input_tokens': 284, 'output_tokens': 249, 'total_tokens': 533}\n",
      "Error no nodes found for: 28707539\n",
      "content='Based on the provided information, I\\'ve extracted the relevant medical relationships that provide answers to the question about hyperbaric oxygenation therapy for necrotizing fasciitis. Here are the structured triples:\\n\\n(\"Necrotizing Fasciitis\", \"IS_ASSOCIATED_WITH\", \"Hyperbaric Oxygenation Therapy\")\\n(\"Hyperbaric Oxygenation Therapy\", \"PREDICTS\", \"Patient Mortality\")\\n(\"Hyperbaric Oxygenation Therapy\", \"PREDICTS\", \"Patient Morbidity\")\\n(\"Hyperbaric Oxygenation Therapy\", \"REQUIRES\", \"Study Results\")\\n(\"Study Results\", \"CAST_DOUTH_ON\", \"Advantage of HBO in reducing patient mortality and morbidity\")\\n(\"Study Results\", \"CAST_DOUTH_ON\", \"Advantage of HBO in reducing patient morbidity\")\\n\\nNote that some relationships may be implied or inferred from the provided text, but I\\'ve only extracted the explicit relationships mentioned.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:25:55.439559Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8789310291, 'load_duration': 39785833, 'prompt_eval_count': 233, 'prompt_eval_duration': 490000000, 'eval_count': 190, 'eval_duration': 8257000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-38283fc4-17a1-49b2-8b52-6e129a07b9d0-0' usage_metadata={'input_tokens': 233, 'output_tokens': 190, 'total_tokens': 423}\n",
      "content='Based on the abstract question and answer, I\\'ve extracted the relevant medical relationships as structured triples:\\n\\n(\"Hawkins sign\", PREDICTS, \"avascular necrosis\")\\n(\"Hawkins sign\", RULES_OUT, \"fractured talus with avascular necrosis\")\\n(\"absence of Hawkins sign\", CONFIRMS, \"fractured talus without avascular necrosis\")\\n\\nNote: The relationships used are:\\n\\n- PREDICTS: indicates that the Hawkins sign can predict a condition\\n- RULES_OUT: indicates that the presence of the Hawkins sign rules out a certain condition\\n- CONFIRMS: indicates that the absence of the Hawkins sign confirms a certain condition\\n\\nPlease note that these relationships are based on the provided answer and may not be universally accepted or validated by medical professionals.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:26:03.118076Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7667906375, 'load_duration': 37811916, 'prompt_eval_count': 232, 'prompt_eval_duration': 474000000, 'eval_count': 165, 'eval_duration': 7154000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-b9400e38-0cf0-4b29-9980-ac364eceab47-0' usage_metadata={'input_tokens': 232, 'output_tokens': 165, 'total_tokens': 397}\n",
      "Error no nodes found for: 24183388\n",
      "content='Here are the extracted relationships in the format you requested:\\n\\n(\"Mandatory general surgery rotation\", IS_ASSOCIATED_WITH, \"Surgical clerkship\")\\n(\"General surgery rotation\", PREDICTS, \"Effective undergraduate surgical education\")\\n(\"Removal of mandatory general surgery rotation\", IMPROVES, \"More effective use of all educational opportunities\")\\n(\"Careful analysis of local programs and facilities\", IS_ASSOCIATED_WITH, \"Suggestion to remove mandatory general surgery rotation from clerkship\")\\n(\"Institutions\", INFLUENCES, \"Decision to remove mandatory general surgery rotation\")\\n\\nNote that some relationships may be implied or inferred from the text, but I\\'ve tried to extract the most direct and relevant ones. Let me know if you\\'d like me to clarify or expand on any of these!' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:26:10.696754Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7568217292, 'load_duration': 42715625, 'prompt_eval_count': 251, 'prompt_eval_duration': 582000000, 'eval_count': 159, 'eval_duration': 6941000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-fb49aa5b-2512-4324-973a-6a1cd9b0d2c5-0' usage_metadata={'input_tokens': 251, 'output_tokens': 159, 'total_tokens': 410}\n",
      "Error no nodes found for: 9645785\n",
      "content='Here are the extracted medical relationships that provide answers to the question:\\n\\n(Phonotraumatic Vocal Pathologies, IS_ASSOCIATED_WITH, Acupuncture)\\n(Phonotraumatic Vocal Pathologies, PREDICTS, Improvement in vocal function)\\n(Vocal fold lesions, IS_ASSOCIATED_WITH, Acupuncture)\\n(Vocal fold lesions, IMPROVES, Healing)\\n\\nNote: The relationships used are:\\n\\n- IS_ASSOCIATED_WITH: indicating a relationship between two entities\\n- PREDICTS: indicating that one entity predicts the occurrence of another\\n- IMPROVES: indicating that one entity improves or enhances the state of another\\n- IS_COST_EFFECTIVE_FOR: not directly applicable in this context, but could be inferred as being useful for treating Phonotraumatic Vocal Pathologies\\n\\nPlease note that some relationships might have been omitted if they were not directly relevant to the question.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:26:19.139388Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8433414541, 'load_duration': 43665916, 'prompt_eval_count': 228, 'prompt_eval_duration': 473000000, 'eval_count': 182, 'eval_duration': 7915000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-54b5e705-b759-4b1a-99b3-59b0fc1e4116-0' usage_metadata={'input_tokens': 228, 'output_tokens': 182, 'total_tokens': 410}\n",
      "Error no nodes found for: 26298839\n",
      "content='Based on the provided abstract and answer, I\\'ve extracted the relevant medical relationships that provide answers to the question. Here are the structured triples:\\n\\n(\"Aneurysm repair\", \"IS_ASSOCIATED_WITH\", \"Ruptured aneurysm\")\\n(\"Elderly patients\", \"IS_A_RISK_FACTOR_FOR\", \"Aneurysmal subarachnoid hemorrhage\")\\n(\"Definitive surgery\", \"IS_AS_EFFECTIVE_AS\", \"Conservative treatment\")\\n(\"Better prognosis\", \"PREDICTS\", \"Ruptured aneurysm repair in the elderly\")\\n(\"Elderly patients with aSAH\", \"IS_USEFUL_FOR\", \"Aneurysm repair\")\\n\\nNote that some relationships may be implied or inferred from the provided text, but I\\'ve only extracted the most direct and explicit connections.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:26:27.261357Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8111266792, 'load_duration': 40133417, 'prompt_eval_count': 261, 'prompt_eval_duration': 592000000, 'eval_count': 172, 'eval_duration': 7477000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-19fe7f2d-bfa7-460e-9275-23e7b954cfa7-0' usage_metadata={'input_tokens': 261, 'output_tokens': 172, 'total_tokens': 433}\n",
      "content='Here are the extracted relationships in the format you requested:\\n\\n(\"Structural characteristics of a practice\", \"IS_ASSOCIATED_WITH\", \"uptake of a new IT facility\")\\n(\"Post-graduate education\", \"REDUCES_RISK_OF\", \"non-uptake of an information technology innovation\")\\n(\"Practice nurse use\", \"PREDICTS\", \"sustained and rising uptake of the diabetes system\")\\n(\"Practice nurse use\", \"IS_ASSOCIATED_WITH\", \"spreading uptake beyond initial GP enthusiasts\")\\n(\"Structural characteristics of a practice\", \"IS_COST_EFFECTIVE_FOR\", \"non-uptake of an information technology innovation\")\\n(\"Post-graduate education\", \"IS_ASSOCIATED_WITH\", \"critical in spreading uptake\")\\n\\nNote that some relationships may be implied or suggested by the text, but not explicitly stated. These extracted triples are based on the most direct and clear connections between entities as described in the abstract question.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:26:36.12845Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8856288958, 'load_duration': 41499958, 'prompt_eval_count': 271, 'prompt_eval_duration': 593000000, 'eval_count': 189, 'eval_duration': 8220000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-550d5ebc-5081-424a-bec3-86b29de76c94-0' usage_metadata={'input_tokens': 271, 'output_tokens': 189, 'total_tokens': 460}\n",
      "content='Based on the abstract question and answer, I\\'ve extracted some medical relationships that provide answers to the question. Here are the structured triples:\\n\\n(\"Well-differentiated HCC\", \"IS_A_RISK_FACTOR_FOR\", \"Early cancer\")\\n(\"Well-differentiated HCC\", \"PREDICTS\", \"Poor prognosis\")\\n(\"Well-differentiated HCC\", \"WORSENS\", \"Disease-free survival\")\\n(\"L-Differentiated HCC\", \"IS_ASSOCIATED_WITH\", \"Significant difference in disease-free survival\")\\n(\"L-Differentiated HCC\", \"IMPROVES\", \"Disease-free survival\")\\n\\nNote that these relationships are inferred from the answer and may not be explicitly stated in all medical literature. However, they provide a logical connection between the concepts.\\n\\nAlso, here are some additional relationships that might be relevant:\\n\\n(\"Hepatocellular carcinoma\", \"IS_A_RISK_FACTOR_FOR\", \"Liver cancer\")\\n(\"Hepatocellular carcinoma\", \"PREDICTS\", \"Prognosis\")\\n(\"Disease-free survival\", \"IMPROVES\", \"Quality of life\")\\n\\nThese relationships are not directly related to the question, but they provide additional context and insights into the topic.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:26:47.517667Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11378146125, 'load_duration': 42061750, 'prompt_eval_count': 246, 'prompt_eval_duration': 478000000, 'eval_count': 247, 'eval_duration': 10856000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-d4711f0d-8630-498a-8118-d457d2133962-0' usage_metadata={'input_tokens': 246, 'output_tokens': 247, 'total_tokens': 493}\n",
      "content='Here are the extracted medical relationships that provide answers to the question as structured triples:\\n\\n(\"Follow-up recommendations\", PREDICTS, \"Patient adherence\")\\n(\"Abnormal Papanicolaou smears\", IS_ASSOCIATED_WITH, \"Low adherence\")\\n(\"Family planning clinic population\", INFLUENCES, \"Adherence to follow-up\")\\n(\"Reminders\", IMPROVES, \"Adherence\")\\n(\"Up to 3 reminders\", IS_MORE_EFFECTIVE_THAN, \"No reminders\")\\n(\"Effective methods for improving adherence\", IS_COST_EFFECTIVE_FOR, \"Allocating resources\")\\n\\nNote: Some relationships may be implied or inferred from the text, but I\\'ve tried to extract the most direct and relevant ones.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:26:54.421572Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6894286666, 'load_duration': 41913583, 'prompt_eval_count': 268, 'prompt_eval_duration': 593000000, 'eval_count': 143, 'eval_duration': 6258000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-a51192a6-875e-4251-9dd4-7114ee647bd2-0' usage_metadata={'input_tokens': 268, 'output_tokens': 143, 'total_tokens': 411}\n",
      "Error no nodes found for: 10575390\n",
      "content='Here are the extracted medical relationships in the format you requested:\\n\\n(\"Real-time PCR approach\", PREDICTS, \"Biomolecular identification of allergenic pollen\")\\n(\"Real-time PCR approach\", IMPROVES, \"Aerobiological monitoring\")\\n(\"Multiplex real-time PCR\", IS_ASSOCIATED_WITH, \"High-throughput molecular methods\")\\n(\"Multiplex real-time PCR\", PREDICTS, \"Simultaneous detection of different taxa\")\\n(\"Pollen mixes\", WORSENS, \"Accuracy in pollen identification and quantification\")\\n(\"Real-time PCR approach\", IS_COST_EFFECTIVE_FOR, \"Aerobiological monitoring\")\\n\\nNote: Some relationships may be implied or suggested by the text, but I\\'ve only extracted explicit statements.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:27:01.572098Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7139879459, 'load_duration': 42077042, 'prompt_eval_count': 258, 'prompt_eval_duration': 589000000, 'eval_count': 150, 'eval_duration': 6507000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-fc11aa65-169f-4cd7-85d4-71f1c4a7fc7f-0' usage_metadata={'input_tokens': 258, 'output_tokens': 150, 'total_tokens': 408}\n",
      "Error no nodes found for: 20084845\n",
      "content='Based on the abstract question and answer, I\\'ve extracted the relevant medical relationships that provide answers to the question. Here are the structured triples:\\n\\n(\"Diabetes mellitus\", \"IS_ASSOCIATED_WITH\", \"FDG-PET\")\\n(\"Cervical cancer\", \"PREDICTS\", \"Diagnosis\")\\n(\"Non-DM patients\", \"IS_COMPARED_TO\", \"PET in cervical cancer patients with mild to moderate DM\")\\n(\"Accuracy of PET\", \"IS_REDUCED_IN\", \"Diabetes mellitus\")\\n(\"Mild to moderate DM\", \"IS_COMPARED_TO\", \"Non-DM patients\")\\n(\"FDG-PET\", \"IS_AS_EFFECTIVE_AS\", \"Accuracy of PET in non-DM patients\")\\n\\nNote that some relationships may be implied or inferred from the answer, but I\\'ve only extracted the explicit ones mentioned.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:27:09.490588Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7911782791, 'load_duration': 41566250, 'prompt_eval_count': 234, 'prompt_eval_duration': 475000000, 'eval_count': 171, 'eval_duration': 7393000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-79c5e08d-804c-427a-8e9e-0d294b6af596-0' usage_metadata={'input_tokens': 234, 'output_tokens': 171, 'total_tokens': 405}\n",
      "content='Here are the extracted medical relationships in the format you requested:\\n\\n(\"Ophthalmic pathology and basic science research\", PREDICTS, \"Improvements in excimer laser keratorefractive surgery\")\\n(\"Ophthalmic pathology and basic science research\", IS_ASSOCIATED_WITH, \"Corneal biomechanics\")\\n(\"Ophthalmic pathology and basic science research\", REDUCES_RISK_OF, \"Corneal haze\")\\n(\"Conventional LASIK or PRK\", WORSENS, \"Wound healing issues\")\\n(\"Advanced Surface Ablation (ASA)\", IS_A_RISK_FACTOR_FOR, \"Corneal haze\")\\n(\"Sub-Bowman\\'s Keratomileusis (SBK)\", IS_A_RISK_FACTOR_FOR, \"Corneal haze\")\\n(\"Ophthalmic pathology and basic science research\", PREDICTS, \"Advantages of SBK over conventional LASIK or PRK\")\\n(\"Advanced Surface Ablation (ASA)\", IS_MORE_EFFECTIVE_THAN, \"Conventional LASIK or PRK\")\\n(\"Sub-Bowman\\'s Keratomileusis (SBK)\", IS_MORE_EFFECTIVE_THAN, \"Conventional LASIK or PRK\")\\n\\nNote: Some relationships may be implied but not explicitly stated in the original text. These extracted triples are based on the most likely interpretation of the provided information.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:27:22.848727Z', 'done': True, 'done_reason': 'stop', 'total_duration': 13351546667, 'load_duration': 41118417, 'prompt_eval_count': 298, 'prompt_eval_duration': 707000000, 'eval_count': 271, 'eval_duration': 12602000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-64b18a98-3ed7-4021-88f1-1c639a51283f-0' usage_metadata={'input_tokens': 298, 'output_tokens': 271, 'total_tokens': 569}\n",
      "Error no nodes found for: 18269157\n",
      "content='Based on the abstract question and answer, here are the extracted medical relationships as structured triples:\\n\\n(\"Radiotherapy\", \"IS_ASSOCIATED_WITH\", \"Primary Rectal Cancer\")\\n(\"Pelvic Exenteration\", \"TREATS\", \"Locally Recurrent Rectal Cancer\")\\n(\"Radiotherapy\", \"REDUCES_RISK_OF\", \"Oncologic Outcomes\")\\n(\"Patients who previously received radiotherapy\", \"HAS\", \"Worse Oncologic Outcomes\")\\n(\"Patients who had not received radiotherapy\", \"HAS\", \"Better Oncologic Outcomes\")\\n\\nNote: The relationship \"HAS\" is not one of the original relationships listed, but it was inferred to complete the logical connection between the entities.\\n\\nAlso, note that the answer does not explicitly mention the relationship between radiotherapy and pelvic exenteration for recurrent rectal cancer. However, based on the context, we can infer a negative association between radiotherapy and improved outcomes after pelvic exenteration:\\n\\n(\"Radiotherapy\", \"WORSENS\", \"Outcomes After Pelvic Exenteration\")\\n(\"Pelvic Exenteration\", \"IMPROVES\", \"Oncologic Outcomes\")\\n\\nPlease note that these relationships are inferred based on the provided answer and may not be universally accepted or validated.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:27:35.473463Z', 'done': True, 'done_reason': 'stop', 'total_duration': 12606792500, 'load_duration': 33874709, 'prompt_eval_count': 245, 'prompt_eval_duration': 525000000, 'eval_count': 253, 'eval_duration': 12046000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-37ba7e9f-b664-43fe-a859-2c3a2bc437d6-0' usage_metadata={'input_tokens': 245, 'output_tokens': 253, 'total_tokens': 498}\n",
      "content='Based on the abstract question and answer, I\\'ve extracted the relevant medical relationships to build a knowledge graph. Here are the structured triples:\\n\\n(\"Lymphedema\", \"IS_ASSOCIATED_WITH\", \"Circumference measurements\")\\n(\"Circumference measurements\", \"PREDICTS\", \"Early lymphedema cases\")\\n(\"Academic trial\", \"IS_A_RISK_FACTOR_FOR\", \"5% increase in circumference measurements\")\\n(\"Practicing surgeon\", \"CAN_DETECT\", \"Early lymphedema cases\")  # Added this relationship\\n(\"Early lymphedema cases\", \"IS_ASSOCIATED_WITH\", \"Lymphedema\")\\n\\nNote: I\\'ve added the relationship \"CAN_DETECT\" to imply that a practicing surgeon can detect early lymphedema cases, although it\\'s not explicitly stated in the original answer. This relationship is inferred based on the context of the question and answer.\\n\\nAlso, I\\'ve used the relationship \"IS_ASSOCIATED_WITH\" to connect Lymphedema with Circumference measurements, as they are related concepts in the context of lymphedema detection. Similarly, I\\'ve used this relationship to connect Early lymphedema cases with Lymphedema, as they are closely related.\\n\\nPlease let me know if you\\'d like me to add or modify any relationships!' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:27:48.860192Z', 'done': True, 'done_reason': 'stop', 'total_duration': 13374728916, 'load_duration': 43934041, 'prompt_eval_count': 220, 'prompt_eval_duration': 528000000, 'eval_count': 266, 'eval_duration': 12801000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-05ae0aca-b98b-4789-ab53-d640a4906e19-0' usage_metadata={'input_tokens': 220, 'output_tokens': 266, 'total_tokens': 486}\n",
      "content='Here are the extracted medical relationships that provide answers to the question as structured triples:\\n\\n(\"Global Management (GM)\", \"IS_ASSOCIATED_WITH\", \"Fewer procedures\")\\n(\"Synchronous Liver Metastases (SLM)\", \"IS_ASSOCIATED_WITH\", \"Longer delay\")\\n(\"Synchronous Liver Metastases (SLM)\", \"IS_ASSOCIATED_WITH\", \"Increased use of chemotherapy\")\\n(\"Global Management (GM)\", \"REDUCES_RISK_OF\", \"Higher disease-free survival after SLM resection\")\\n(\"Surgical Management (SM)\", \"IS_A_RISK_FACTOR_FOR\", \"Disease-free survival\")\\n\\nNote: The relationships used are:\\n\\n- IS_ASSOCIATED_WITH: indicating an association between two entities\\n- REDUCES_RISK_OF: indicating that one entity reduces the risk of another\\n- IS_A_RISK_FACTOR_FOR: indicating that one entity is a risk factor for another\\n- PREDICTS: not explicitly mentioned in the question, but implied by the relationship \"Global Management (GM) was associated with fewer procedures\"\\n- IMPROVES: not explicitly mentioned in the question, but implied by the relationship \"Global Management (GM) reduces the risk of higher disease-free survival after SLM resection\"' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:28:01.450471Z', 'done': True, 'done_reason': 'stop', 'total_duration': 12576978917, 'load_duration': 41304625, 'prompt_eval_count': 262, 'prompt_eval_duration': 659000000, 'eval_count': 253, 'eval_duration': 11875000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-f5e7c131-8b54-4a86-a33a-da184f4291c2-0' usage_metadata={'input_tokens': 262, 'output_tokens': 253, 'total_tokens': 515}\n",
      "content='Here are the extracted medical relationships that provide answers to the question as structured triples:\\n\\n(\"Motion Perception Deficit in Schizophrenia\", \"IS_A_RISK_FACTOR_FOR\", \"Eye-Tracking Abnormality\")\\n(\"Speed Discrimination\", \"IS_ASSOCIATED_WITH\", \"Motion Perception Deficit in Schizophrenia\")\\n(\"Generating Feedback Information from Eye Movements\", \"IS_A_RISK_FACTOR_FOR\", \"Motion Perception Deficit in Schizophrenia\")\\n(\"Impairment of Generating or Integrating Feedback Information\", \"REDUCES_RISK_OF\", \"Eye-Tracking Abnormality\")\\n(\"Concurrent Measurement of Eye Movements\", \"PREDICTS\", \"Understanding Interactions between Motion Perception and Eye Movements\")\\n\\nNote: Some relationships may be implied but not explicitly stated in the provided text. These triples are based on the information that can be inferred from the abstract question and answer.\\n\\nAlso, note that some relationships might seem counterintuitive or require additional context to fully understand. For example, \"Impairment of Generating or Integrating Feedback Information\" reduces the risk of eye-tracking abnormality, but it\\'s not a direct consequence of motion perception deficit in schizophrenia.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:28:12.722541Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11247931500, 'load_duration': 44890208, 'prompt_eval_count': 277, 'prompt_eval_duration': 625000000, 'eval_count': 238, 'eval_duration': 10576000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-3d6afd62-3843-485c-9765-aa9d6c6fcbb0-0' usage_metadata={'input_tokens': 277, 'output_tokens': 238, 'total_tokens': 515}\n",
      "content='Based on the abstract question and answer, I\\'ve extracted the following medical relationships that provide answers to the question:\\n\\n(\"Transgastric endoscopic splenectomy\", \"IS_A_RISK_FACTOR_FOR\", \"Splenectomy\")\\n(\"Transgastric endoscopic splenectomy\", \"PREDICTS\", \"Long-term survival experiments\")\\n(\"Porcine model\", \"IS_ASSOCIATED_WITH\", \"Transgastric endoscopic splenectomy\")\\n\\nNote that the answer does not explicitly state a relationship between Transgastric endoscopic splenectomy and long-term survival, but it implies that the procedure is being studied to predict its effects. Similarly, the answer does not provide information on whether Splenectomy is a risk factor for Transgastric endoscopic splenectomy.\\n\\nIf we consider the question \"is it possible?\" as asking about the feasibility of the procedure, we can add another relationship:\\n\\n(\"Transgastric endoscopic splenectomy\", \"IS_COST_EFFECTIVE_FOR\", \"Porcine model\")\\n\\nThis relationship implies that the study is being conducted on a porcine model to assess its cost-effectiveness.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:28:23.521162Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10784851750, 'load_duration': 44702500, 'prompt_eval_count': 227, 'prompt_eval_duration': 476000000, 'eval_count': 232, 'eval_duration': 10262000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-730978ff-b784-4911-bf53-7fa2f562446b-0' usage_metadata={'input_tokens': 227, 'output_tokens': 232, 'total_tokens': 459}\n",
      "content='Here are the extracted medical relationships that provide answers to the question:\\n\\n(\"Fournier\\'s gangrene\", \"IS_A_RISK_FACTOR_FOR\", \"Surgical emergency\")\\n(\"Fournier\\'s gangrene\", \"PREDICTS\", \"Outcome\")\\n(\"Fournier\\'s gangrene\", \"IS_ASSOCIATED_WITH\", \"Prompt radical debridement\")\\n(\"Fournier\\'s gangrene\", \"IS_COST_EFFECTIVE_FOR\", \"Early recognition\")\\n(\"Interval from onset of clinical symptoms to initial surgical intervention\", \"IS_A_RISK_FACTOR_FOR\", \"Poor outcome\")\\n(\"Interval from onset of clinical symptoms to initial surgical intervention\", \"PREDICTS\", \"Outcome\")\\n(\"Prompt radical debridement\", \"IMPROVES\", \"Outcome\")\\n\\nNote: Some relationships may be implied or inferred, but I\\'ve tried to extract the most direct and relevant ones based on the provided text.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:28:32.180743Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8647484875, 'load_duration': 45091834, 'prompt_eval_count': 259, 'prompt_eval_duration': 593000000, 'eval_count': 181, 'eval_duration': 8008000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-c1b8fd26-8690-4c3d-b728-eb8cd42cd870-0' usage_metadata={'input_tokens': 259, 'output_tokens': 181, 'total_tokens': 440}\n",
      "content='Here are the extracted medical relationships that provide answers to the question:\\n\\n(\"Kidney transplant\", \"IS_A_RISK_FACTOR_FOR\", \"Elderly donor kidney\")\\n(\"Young recipient\", \"IS_ASSOCIATED_WITH\", \"Good renal function\")\\n(\"Patient survival\", \"PREDICTS\", \"Graft survival\")\\n(\"Renal function\", \"IS_MORE_EFFECTIVE_THAN\", \"Renal function in elderly donors\")\\n(\"Kidney transplant from elderly donors\", \"IS_COST_EFFECTIVE_FOR\", \"Young recipient\")\\n(\"Elderly donor kidney\", \"WORSENS\", \"Patient and graft survival\")\\n\\nNote: Some relationships may seem counterintuitive, but they are based on the original text. For example, \"Elderly donor kidney\" worsens patient and graft survival, but this is because renal function is better in young donors.\\n\\nAlso, note that some relationships were not explicitly mentioned in the original text, but can be inferred from it. For example, \"Kidney transplant\" is associated with \"Is_A_Risk_FACTOR_FOR\", as implied by the context of the question.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:28:42.3097Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10119965542, 'load_duration': 41915792, 'prompt_eval_count': 240, 'prompt_eval_duration': 479000000, 'eval_count': 220, 'eval_duration': 9597000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-6e6bbfee-cdcc-4ad6-8f31-c58a0b096756-0' usage_metadata={'input_tokens': 240, 'output_tokens': 220, 'total_tokens': 460}\n",
      "content='Here are the extracted medical relationships that provide answers to the question as structured triples:\\n\\n(\"Medicaid Demonstration\", \"IS_ASSOCIATED_WITH\", \"Florida\\'s Medicaid program\")\\n(\"PMPM expenditures\", \"REDUCES_RISK_OF\", \"lower expenditures\")\\n(\"Demonstration PSNs\", \"IS_ASSOCIATED_WITH\", \"Florida\\'s Medicaid program\")\\n(\"Demonstration HMOs\", \"IS_ASSOCIATED_WITH\", \"Florida\\'s Medicaid program\")\\n(\"PSNs\", \"IS_MORE_EFFECTIVE_THAN\", \"Demonstration HMOs\")\\n(\"Medicaid enrollees\", \"TREATS\", \"care delivery model\")\\n(\"PMPM expenditures\", \"WORSENS\", \"expenditures in traditional HMOs\")\\n(\"PSNs\", \"PREDICTS\", \"lower expenditures\")\\n\\nNote: Some relationships may be implied or inferred from the text, but I\\'ve tried to stick to the explicit relationships mentioned. Let me know if you\\'d like me to clarify any of these!' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:28:51.843487Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9522515250, 'load_duration': 41205917, 'prompt_eval_count': 261, 'prompt_eval_duration': 593000000, 'eval_count': 202, 'eval_duration': 8886000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-48556635-1f91-40c7-b0d3-a65a15c14628-0' usage_metadata={'input_tokens': 261, 'output_tokens': 202, 'total_tokens': 463}\n",
      "content='Here are the extracted medical relationships that provide answers to the question as structured triples:\\n\\n(\"Carotid Artery Stenosis\", \"IS_ASSOCIATED_WITH\", \"Selective Screening\")\\n(\"Selective Screening\", \"REDUCES_RISK_OF\", \"40% of Carotid Artery Stenosis Screening Load\")\\n(\"Carotid Artery Stenosis\", \"IS_ASSOCIATED_WITH\", \"History of Cerebrovascular Disease\")\\n(\"History of Cerebrovascular Disease\", \"IS_ASSOCIATED_WITH\", \"Selective Screening\")\\n(\"Carotid Artery Stenosis\", \"IS_ASSOCIATED_WITH\", \"Diabetes Mellitus\")\\n(\"Diabetes Mellitus\", \"IS_ASSOCIATED_WITH\", \"Selective Screening\")\\n(\"Carotid Artery Stenosis\", \"IS_ASSOCIATED_WITH\", \"Peripheral Vascular Disease\")\\n(\"Peripheral Vascular Disease\", \"IS_ASSOCIATED_WITH\", \"Selective Screening\")\\n\\nThese triples represent the associations between carotid artery stenosis and selective screening, as well as the associations with other conditions that may warrant selective screening.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-04-04T18:29:02.211142Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10356483375, 'load_duration': 38561208, 'prompt_eval_count': 260, 'prompt_eval_duration': 591000000, 'eval_count': 222, 'eval_duration': 9725000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-5644eb8c-3eb6-4e3b-8caf-d496ccc782c6-0' usage_metadata={'input_tokens': 260, 'output_tokens': 222, 'total_tokens': 482}\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "combined_formatted_graph = []\n",
    "bad_abstracts = []\n",
    "\n",
    "for i, (entry_id, row) in enumerate(abstracts.iterrows()):\n",
    "    if i >= 50: # Limits to 50 abstracts\n",
    "        break\n",
    "\n",
    "    structured_text = create_query(row[\"title\"], row[\"answer\"])\n",
    "    response = llm.invoke(structured_text)\n",
    "    print(response)\n",
    "    \n",
    "    # Extract the actual text from the LLM response\n",
    "    raw_output = response.content\n",
    "\n",
    "    raw_output = response.content\n",
    "\n",
    "    # Extract (Entity1, Relationship, Entity2) triples using regex\n",
    "    matches = [\n",
    "        (e1.strip(), rel.strip(), e2.strip())\n",
    "        for e1, rel, e2 in re.findall(r'^(.*?),\\s*(.*?),\\s*(.*?)$', raw_output, re.MULTILINE)\n",
    "        if e1.strip().upper() not in {\"START\", \"FINISH\"} and e2.strip().upper() not in {\"START\", \"FINISH\"}\n",
    "    ]\n",
    "\n",
    "    print(f\"matches:\\n{matches}\")\n",
    "\n",
    "    # Convert extracted triples into nodes and relationships\n",
    "    nodes = set()\n",
    "    relationships = []\n",
    "\n",
    "    for entity1, relation, entity2 in matches:\n",
    "        nodes.add(entity1)\n",
    "        nodes.add(entity2)\n",
    "        relationships.append((entity1, relation, entity2))\n",
    "\n",
    "    # Convert to Full Node-Relationship-Node Format\n",
    "    formatted_graph = [f\"({e1}) -[:{r.replace(' ', '_').upper()}]-> ({e2})\" for e1, r, e2 in relationships]\n",
    "    if len(formatted_graph) == 0:\n",
    "        print(f\"Error no nodes found for: {entry_id}\")\n",
    "        bad_abstracts.append(entry_id)\n",
    "\n",
    "    combined_formatted_graph.extend(formatted_graph)\n",
    "\n",
    "print(\"Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph_output.txt', 'w') as f:\n",
    "    for item in combined_formatted_graph:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cleaned and saved as 'graph_output.txt'\n"
     ]
    }
   ],
   "source": [
    "# Function to remove quotes\n",
    "def clean_file(text):\n",
    "    return text.replace('\"', '').replace(\"'\", '').replace(\"((\", \"(\").replace(\"))\", \")\")\n",
    "\n",
    "# Read the content of the output file\n",
    "with open('graph_output.txt', 'r') as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "# Remove quotes from the file content\n",
    "cleaned_content = clean_file(file_content)\n",
    "\n",
    "# Write the cleaned content back to the file\n",
    "with open('graph_output.txt', 'w') as cleaned_file:\n",
    "    cleaned_file.write(cleaned_content)\n",
    "\n",
    "print(\"File cleaned and saved as 'graph_output.txt'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_explore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
